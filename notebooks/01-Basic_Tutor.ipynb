{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiYjEFg2zS4n"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ai-tutor-rag-system/blob/main/notebooks/01-Basic_Tutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMXyyXD0xix9"
      },
      "source": [
        "# Install Packages and Setup Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4Q0N2omkAoZ",
        "outputId": "6dcb78c8-83a1-4e8c-825d-8e56a6c277f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/951.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.6/951.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m942.1/951.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.0/951.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai==1.107.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xxK7EAAvr2aT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the \"OPENAI_API_KEY\" in the Python environment. Will be used by OpenAI client later.\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68RbStS-xpbL"
      },
      "source": [
        "# Load the API client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "La8hdWqJkFkh"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Defining the \"client\" object that enables\n",
        "# us to connect to OpenAI API endpoints.\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC-sa_uv6J2C"
      },
      "source": [
        "# Query the API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7JRrn0uIsBfg"
      },
      "outputs": [],
      "source": [
        "# Define two questions: 1) Related to AI, 2) Unrelated topic.\n",
        "# These questions will be used to evaluate model's performance.\n",
        "QUESTION_AI = \"List a number of famous artificial intelligence frameworks?\"\n",
        "QUESTION_NOT_AI = (\n",
        "    \"What is the name of the highest mountain in the world and its height?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_ai_tutor(question):\n",
        "    try:\n",
        "        # System instructions for the AI tutor specialized in AI-related questions\n",
        "        instructions = (\n",
        "            \"You are an AI tutor specialized in answering artificial intelligence-related questions. \"\n",
        "            \"Only answer AI-related questions, else say that you cannot answer this question.\"\n",
        "        )\n",
        "\n",
        "        # Call the OpenAI Responses API\n",
        "        response = client.responses.create(\n",
        "            model=\"gpt-5-mini\",\n",
        "            reasoning={'effort':'minimal'},\n",
        "            instructions=instructions,  # System-level guidance\n",
        "            input=f\"Please provide an informative and accurate answer to the following question.\\nQuestion: {question}\\nAnswer:\",\n",
        "        )\n",
        "\n",
        "        # Return the AI's response using the output_text helper\n",
        "        return response.output_text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n"
      ],
      "metadata": {
        "id": "sROAUTEL1F86"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_dbwURpufR7",
        "outputId": "4e24980f-9d4f-459f-b044-61a8529d148c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are many well-known artificial intelligence frameworks and libraries, grouped by primary use. Note that most frameworks overlap (e.g., deep learning frameworks used for research and production ML).\n",
            "\n",
            "General-purpose deep learning frameworks\n",
            "- TensorFlow (Google) — large ecosystem for research and production; TF 2.x emphasizes Keras-style APIs.\n",
            "- PyTorch (Meta/Facebook) — flexible imperative-style DL framework popular in research; TorchScript and PyTorch Serve for production.\n",
            "- JAX (Google) — composable, high-performance numerical computing with automatic differentiation and XLA compilation; popular for research and large-scale models.\n",
            "- MXNet (Apache) — scalable deep learning framework used by some production systems.\n",
            "- Chainer — early flexible DL framework; architecture influenced later tools (less commonly used now).\n",
            "\n",
            "High-level libraries / model APIs\n",
            "- Keras — high-level neural-network API (now integrated into TensorFlow).\n",
            "- Hugging Face Transformers — state-of-the-art pre-trained models and utilities for NLP, multimodal, and foundation models.\n",
            "- FastAI — high-level PyTorch library for fast prototyping and best-practice recipes.\n",
            "\n",
            "Probabilistic programming / Bayesian inference\n",
            "- Pyro (Uber) — probabilistic programming on top of PyTorch.\n",
            "- Edward / Edward2 — probabilistic modeling (TensorFlow/TFP ecosystem).\n",
            "- TensorFlow Probability — probabilistic building blocks for TensorFlow.\n",
            "- Stan — probabilistic modeling and MCMC.\n",
            "\n",
            "Classical ML libraries\n",
            "- scikit-learn — widely used library for classical ML algorithms and pipelines (classification, regression, clustering, preprocessing).\n",
            "- XGBoost — optimized gradient boosting decision trees.\n",
            "- LightGBM — Microsoft’s gradient boosting framework optimized for speed/memory.\n",
            "- CatBoost — gradient boosting framework from Yandex, handles categorical features well.\n",
            "\n",
            "Reinforcement learning frameworks\n",
            "- RLlib (Ray) — scalable RL library.\n",
            "- OpenAI Gym — standard environments and API for RL research and benchmarking.\n",
            "- Stable Baselines3 — high-level RL algorithms implemented in PyTorch.\n",
            "- Dopamine (Google) — research RL framework focusing on simplicity and reproducibility.\n",
            "\n",
            "Distributed training / scalability\n",
            "- Horovod (Uber) — distributed training for TensorFlow, PyTorch, MXNet.\n",
            "- Ray — distributed execution framework for scaling ML workloads and RL.\n",
            "- DeepSpeed (Microsoft) — optimization and efficient training for large models (FP16, ZeRO).\n",
            "- FairScale — PyTorch tools for model parallelism and optimization.\n",
            "\n",
            "Model deployment / serving / inference\n",
            "- TensorFlow Serving — serving system for TensorFlow models.\n",
            "- TorchServe — model serving for PyTorch.\n",
            "- ONNX (Open Neural Network Exchange) — model interchange format; ONNX Runtime for cross-platform inference.\n",
            "- NVIDIA TensorRT — high-performance inference optimizer for NVIDIA GPUs.\n",
            "\n",
            "Vision / specialized libraries\n",
            "- Detectron2 (Facebook) — object detection and segmentation in PyTorch.\n",
            "- MMDetection / MMSegmentation (OpenMMLab) — modular vision toolkits.\n",
            "- OpenCV — computer vision library with ML-related modules.\n",
            "\n",
            "Tools for model interpretability / evaluation\n",
            "- SHAP — model-agnostic explanation method.\n",
            "- LIME — local interpretable model-agnostic explanations.\n",
            "- Captum — PyTorch model interpretability library.\n",
            "\n",
            "AutoML / model search\n",
            "- AutoKeras — AutoML for Keras/TensorFlow.\n",
            "- AutoGluon — AutoML toolkit from AWS.\n",
            "- Google AutoML / Vertex AI — managed AutoML services.\n",
            "\n",
            "Large-model / multimodal toolkits\n",
            "- Megatron-LM (NVIDIA/Google collaborations) — large-language-model training framework.\n",
            "- T5 / Flaxformer implementations (Google, Hugging Face) — transformer model toolkits in JAX/Flax or TensorFlow.\n",
            "- DeepSpeed + Megatron combinations for training huge transformer models.\n",
            "\n",
            "Simulation / robotics\n",
            "- CARLA (autonomous driving simulator).\n",
            "- MuJoCo (physics engine used in robotics and RL).\n",
            "\n",
            "This is not exhaustive but covers the most widely used AI frameworks and libraries across research and production. If you want recommendations tailored to a specific task (e.g., NLP, CV, RL, production deployment, or training large models), tell me the use case and constraints and I’ll suggest the most appropriate frameworks.\n"
          ]
        }
      ],
      "source": [
        "# Ask the AI-related question.\n",
        "RES_AI = ask_ai_tutor(QUESTION_AI)\n",
        "print(RES_AI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37YuVJQquhpN",
        "outputId": "529065da-a7fb-40f0-c08a-f951f42b9f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can only answer questions related to artificial intelligence. I cannot answer this question.\n"
          ]
        }
      ],
      "source": [
        "# Ask the unrelated question.\n",
        "RES_NOT_AI = ask_ai_tutor(QUESTION_NOT_AI)\n",
        "print(RES_NOT_AI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRBgk6WToIK0"
      },
      "source": [
        "# History\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5-mini\",\n",
        "    reasoning={'effort':'minimal'},\n",
        "    instructions=\"You are an AI tutor specialized in answering artificial intelligence-related questions. Only answer AI-related questions, else say that you cannot answer this question.\",\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Please provide an informative and accurate answer to the following question.\\nQuestion: List a number of famous artificial intelligence frameworks?\\nAnswer:\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": RES_AI\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Please provide an informative and accurate answer to the following question.\\nQuestion: What is the name of the highest mountain in the world and its height?\\nAnswer:\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": RES_NOT_AI\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Please provide an informative and accurate answer to the following question.\\nQuestion: Can you write a summary of the first suggested AI framework in the first question?\\nAnswer:\",\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.output_text.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMfxRSXx2R-O",
        "outputId": "415b4e0a-bee3-4717-dca8-baeaf8e6d43a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first framework listed earlier was TensorFlow. Here is a concise summary:\n",
            "\n",
            "- What it is: TensorFlow is an open-source machine learning and deep learning framework developed by Google Brain. It provides tools for building, training, and deploying a wide range of ML models, from research prototypes to large-scale production systems.\n",
            "\n",
            "- Key features:\n",
            "  - Computation graphs and eager execution: Originally based on static computation graphs, TensorFlow 2.x adopts eager execution by default while still supporting graph-based workflows (via tf.function) for performance.\n",
            "  - Keras integration: tf.keras is the high-level API for constructing and training neural networks, making TensorFlow more user-friendly.\n",
            "  - Broad ecosystem: Includes TensorFlow Hub (pretrained modules), TensorFlow Lite (mobile/embedded inference), TensorFlow.js (in-browser/in-Node.js ML), TensorFlow Extended (TFX) for production pipelines, and TensorFlow Model Garden (reference models).\n",
            "  - Distributed and accelerated training: Supports multi-GPU and multi-node training, and integrates with accelerators (TPUs) and frameworks like Horovod.\n",
            "  - Deployment and serving: TensorFlow Serving, SavedModel format, and support for exporting to formats like TensorFlow Lite and ONNX for inference across platforms.\n",
            "  - Tooling: TensorBoard for visualization and debugging; TensorFlow Probabilty and TensorFlow Data Services for advanced uses.\n",
            "\n",
            "- Use cases: Computer vision, natural language processing, speech recognition, recommendation systems, reinforcement learning, and scalable production ML.\n",
            "\n",
            "- Strengths: Large ecosystem, strong production deployment tools, comprehensive documentation, and support for mobile/edge/TPU deployments.\n",
            "\n",
            "- Considerations: Some users prefer PyTorch for research due to its Pythonic imperative style; however, TensorFlow 2 has narrowed the usability gap. Model export and serving workflows can add complexity depending on target environment.\n",
            "\n",
            "If you want, I can provide a short code example (training a simple model with tf.keras), point to official resources, or compare TensorFlow vs PyTorch for a specific project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DKCXmzLVxt51"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}