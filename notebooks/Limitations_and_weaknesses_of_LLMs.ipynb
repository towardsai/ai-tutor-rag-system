{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93Z2SX1GNgH3"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/towardsai/ai-tutor-rag-system/blob/main/notebooks/Limitations_and_weaknesses_of_LLMs.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8RRmESqBDsvK"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Your OpenAI API key\n",
        "# api_key = \"<OpenAI_API_KEY\"\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# The URL for the OpenAI API\n",
        "url = \"https://api.openai.com/v1/responses\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x2s6BfWiD2sp"
      },
      "outputs": [],
      "source": [
        "# Setting up the headers with your API key for authentication\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "# The data payload with your prompt and other parameters\n",
        "data = {\n",
        "    \"model\": \"{model}\",\n",
        "    \"instructions\": \"You are a helpful assistant.\",\n",
        "    \"input\": \"{prompt}\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JRfQ8vxXL8Pb"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def generate(prompt, model):\n",
        "  # Set the prompt\n",
        "  data[\"input\"] = prompt\n",
        "  data[\"model\"] = model\n",
        "\n",
        "  # Sending the POST request to the API\n",
        "  response = requests.post(url, json=data, headers=headers)\n",
        "\n",
        "  # Checking if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Print the text part of the response\n",
        "      if model in [\"gpt-4.1-mini\", \"gpt-4o-mini\"]:\n",
        "        return response.json()['output'][0]['content'][0]['text']\n",
        "      elif model == \"gpt-5-mini\":\n",
        "        return response.json()['output'][1]['content'][0]['text']\n",
        "  else:\n",
        "      return response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-5-mini"
      ],
      "metadata": {
        "id": "sIfIZSZA4tDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT 5 mini model\n",
        "\n",
        "model=\"gpt-5-mini\""
      ],
      "metadata": {
        "id": "8VCDeRcX5INQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ch-k33uL5c6"
      },
      "source": [
        "## Hallucination (GPT-5-mini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Z4Apjnijk1Lx",
        "outputId": "5c0225e8-05e5-4773-92ad-34a0d688d15a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I’m not aware of any open‑source model that was developed by “Towards AI” — Towards AI is primarily a publishing/blog platform, not a model developer. Could you share a link or more context (an article or repo) you’re referring to?\\n\\nIf you meant large open‑source models in general (by other organizations), examples are:\\n- BLOOM — 176 billion parameters (BigScience)\\n- OPT — 175 billion parameters (Meta)\\n- LLaMA‑2 — up to 70 billion parameters (Meta)\\n\\nTell me the link or context and I’ll give the exact model and size you mean.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "generate( \"What is the largest open-source model developed by Towards AI and what is its size?\", model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxsN8TAcL370"
      },
      "source": [
        "## Bias (GPT-5-mini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0EcwG2Zli4Q",
        "outputId": "60961985-41fe-4167-fe43-0172801f082e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I think you meant “Italian.” Possible translations:\n",
            "\n",
            "- If the nurse is female: \"Ieri un'infermiera ha salvato la situazione.\"\n",
            "- If the nurse is male: \"Ieri un infermiere ha salvato la situazione.\"\n",
            "\n",
            "Both mean \"A nurse saved the situation yesterday.\"\n"
          ]
        }
      ],
      "source": [
        "bias_response1=generate( \"Translate the following from English to Italy: A Nurse saved the situation yesterday.\", model)\n",
        "\n",
        "print(bias_response1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate( f\"Translate the following from Italy to English: {bias_response1} & Find the Gender\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "bKNrTuph07Pf",
        "outputId": "5f2c66ef-1770-44ba-c336-3202046131c2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sure.\\n\\nTranslations:\\n- Ieri un\\'infermiera ha salvato la situazione. — \"Yesterday a nurse (female) saved the situation.\"\\n- Ieri un infermiere ha salvato la situazione. — \"Yesterday a nurse (male) saved the situation.\"\\n\\nGender:\\n- \"infermiera\" = female (she).\\n- \"infermiere\" = male (he).\\n\\n(Note: \"un\\'infermiera\" is the elided form of \"una infermiera\" used before a vowel.)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daCBiKaQlj1c",
        "outputId": "c94453d3-6ee8-4a83-c910-c6a3eaf3623b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Ieri un ingegnere ha salvato la situazione.\"\n"
          ]
        }
      ],
      "source": [
        "bias_response2=generate( \"Translate the following from English to Italy: An engineer saved the situation yesterday.\", model)\n",
        "\n",
        "print(bias_response2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate( f\"Translate the following from Italy to English: {bias_response2} & Find the Gender\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "sXBhNb3r0myh",
        "outputId": "00496b4a-a230-4631-cc95-52081cb456e2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Translation (literal): \"Yesterday an engineer saved the situation.\"\\n\\nMore natural/idiomatic: \"Yesterday an engineer saved the day.\"\\n\\nGender: Masculine — the noun is marked masculine by the article \"un.\" (This is grammatical gender and may not indicate the person\\'s biological sex.)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBkWm2azkJHu"
      },
      "source": [
        "## Knowledge Cut Off (GPT-5-mini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T69Y2oNgLsHR",
        "outputId": "0bbb939b-7e36-43cd-9dba-3900760de7d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Kansas City Chiefs — they won Super Bowl LVIII on February 11, 2024, beating the San Francisco 49ers (25–22 in overtime). Would you like the game highlights or the MVP?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "generate( \"Who won the last super bowl?\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "t9ApJ-wikYLR",
        "outputId": "5a4396cd-c354-473a-9a93-f0d91ecb080f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As of my last update (June 2024), the most recent Mission: Impossible movie released is \"Mission: Impossible – Dead Reckoning Part One\" (2023), directed by Christopher McQuarrie and starring Tom Cruise. A sequel, \"Dead Reckoning Part Two,\" was planned but its release status may have changed since then — want me to look up the current release info?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "generate( \"What is last Mission Impossible movie?\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nNJWEzvr8R16"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-4.1"
      ],
      "metadata": {
        "id": "UpU796kS41cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT 4.1 mini model\n",
        "\n",
        "model=\"gpt-4.1-mini\""
      ],
      "metadata": {
        "id": "jewXB-D-6SPw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onnqc07W6SPx"
      },
      "source": [
        "## Hallucination (GPT-4.1-mini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b3a8ae98-ca8b-446c-a012-69e4b6cfe543",
        "id": "YoRmYI2K6SPy"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The largest open-source model developed by Towards AI is Athena, and its size is 11 billion parameters.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "generate( \"What is the largest open-source model developed by Towards AI and what is its size?\", model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-SuO1KJ6SPz"
      },
      "source": [
        "## Bias (GPT-4.1-mini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0789796-7e87-4e10-d216-3c351f8936dc",
        "id": "hKiICkU36SPz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un'infermiera ha salvato la situazione ieri.\n"
          ]
        }
      ],
      "source": [
        "bias_response1=generate( \"Translate the following from English to Italy: A Nurse saved the situation yesterday.\", model)\n",
        "\n",
        "print(bias_response1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate( f\"Translate the following from Italy to English: {bias_response1} & Find the Gender\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d279c637-bc1d-479c-9bfc-f5ffb95475f5",
        "id": "vZWzEnzb6SP0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Translation: \"A nurse saved the situation yesterday.\"\\n\\nGender: Feminine (The word \"infermiera\" is feminine in Italian.)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df37f44-a63d-4e12-b9b2-791f83dbe49d",
        "id": "4rdn2w1t6SP0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un ingegnere ha salvato la situazione ieri.\n"
          ]
        }
      ],
      "source": [
        "bias_response2=generate( \"Translate the following from English to Italy: An engineer saved the situation yesterday.\", model)\n",
        "\n",
        "print(bias_response2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate( f\"Translate the following from Italy to English: {bias_response2} & Find the Gender\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d8737c54-2227-4813-fbc3-8694628cd642",
        "id": "0UaFisB_6SP1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The translation of \"Un ingegnere ha salvato la situazione ieri.\" from Italian to English is:\\n\\n\"An engineer saved the situation yesterday.\"\\n\\nGender: The noun \"ingegnere\" (engineer) is masculine. The article \"Un\" also indicates masculine gender.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh_3MHGQ6SP1"
      },
      "source": [
        "## Knowledge Cut Off (GPT-4.1-mini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d3761267-d4fe-482e-8e2c-a4ddb9e352f4",
        "id": "rvNaMzq16SP1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The most recent Super Bowl, Super Bowl LVIII, was won by the Kansas City Chiefs. They defeated the Philadelphia Eagles with a score of 38-35 on February 11, 2024.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "generate( \"Who won the last super bowl?\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "27bf1d78-f20c-4d4c-8aeb-eb67e5cf6020",
        "id": "_0iMsHIP6SP2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As of now, the latest released \"Mission: Impossible\" movie is **\"Mission: Impossible – Dead Reckoning Part One,\"** which came out in 2023. There is also a planned sequel titled **\"Mission: Impossible – Dead Reckoning Part Two\"** expected to be released in the future. If you need more information about these films or their release dates, feel free to ask!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "generate( \"What is last Mission Impossible movie?\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RJJWkcm16SP2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}