{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9bpz99INAc1"
      },
      "source": [
        "# Install Packages and Setup Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BeuFJKlj9jKz",
        "outputId": "122d64c6-ba00-4438-ef3d-429a7dd3afee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/753.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.4/753.4 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q google-generativeai==0.8.5 google-genai==1.27.0 llama-index-llms-google-genai==0.3.0 llama-index==0.13.0 openai==1.92.0 jedi==0.19.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CWholrWlt2OQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Set the following API Keys in the Python environment. Will be used later.\n",
        "# We use OpenAI for the embedding model and Gemini-2.5-flash as our LLM.\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_OPENAI_KEY>\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
        "\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5eV5EnvNCMM"
      },
      "source": [
        "# Load Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-7mRQ-mNJlm"
      },
      "source": [
        "## Download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PsdOdMUNmEi"
      },
      "source": [
        "The dataset includes a subset of the documentation from the Llama-index library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ImRCP7pACaI",
        "outputId": "b5d6e9fc-016d-425d-b9ab-18065cb1ce9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   115  100   115    0     0   1034      0 --:--:-- --:--:-- --:--:--  1026\n",
            "100  570k  100  570k    0     0  2809k      0 --:--:-- --:--:-- --:--:-- 2809k\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o ./llama_index_150k.jsonl https://huggingface.co/datasets/towardsai-buster/llama-index-docs/raw/main/llama_index_data_150k.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZZLK_wyEc-L"
      },
      "source": [
        "## Read File and create LlamaIndex Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miUqycqAEfr7",
        "outputId": "6b65ce8b-115b-4a39-ecd9-b96cd01ae48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 56\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import Document\n",
        "import json\n",
        "\n",
        "\n",
        "def create_docs(input_file: str) -> list[Document]:\n",
        "    documents = []\n",
        "    with open(input_file, \"r\") as f:\n",
        "        for idx, line in enumerate(f, start=1):\n",
        "\n",
        "          data = json.loads(line)\n",
        "\n",
        "          required_keys = {\"doc_id\", \"content\", \"url\", \"name\", \"tokens\", \"source\"}\n",
        "          if not required_keys.issubset(data):\n",
        "              print(f\"Missing keys in line {idx}: {required_keys - set(data)}\")\n",
        "              continue\n",
        "\n",
        "          documents.append(\n",
        "              Document(\n",
        "                  doc_id=data[\"doc_id\"],\n",
        "                  text=data[\"content\"],\n",
        "                  metadata={  # type: ignore\n",
        "                      \"url\": data[\"url\"],\n",
        "                      \"title\": data[\"name\"],\n",
        "                      \"tokens\": data[\"tokens\"],\n",
        "                      \"source\": data[\"source\"],\n",
        "                  },\n",
        "                  excluded_llm_metadata_keys=[\n",
        "                      \"title\",\n",
        "                      \"tokens\",\n",
        "                      \"source\",\n",
        "                  ],\n",
        "                  excluded_embed_metadata_keys=[\n",
        "                      \"url\",\n",
        "                      \"tokens\",\n",
        "                      \"source\",\n",
        "                  ],\n",
        "              )\n",
        "          )\n",
        "\n",
        "    return documents\n",
        "\n",
        "\n",
        "# Convert the texts to Document objects.\n",
        "documents = create_docs(\"llama_index_150k.jsonl\")\n",
        "print(f\"Number of documents: {len(documents)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86yksB9K571"
      },
      "source": [
        "# Generate Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ef19a27b3ec341079824968a9eb360ae",
            "1f5d0529325f48cab8a951dfe6859e75",
            "22a620bac4e44273a6b6d274d49feba4",
            "9683e2507a84488d9d7a509eed8c7c81",
            "3c43c9ce47a745b3ae4a73373a1a8198",
            "9fc89c07b44343cd939ec5aeb4b417b2",
            "1c31b247667043edb97292773264e46e",
            "d5caef618fbe415f966f88613623f91a",
            "a7295a321785440aa8d33ffb9cd20f8e",
            "6e668fd18f1747e7a7094cffd90a51e0",
            "5c089e3b178a42eea20ef58fce9071b2",
            "7fb2fb9864894984be397f293b2da32d",
            "4ce6ea118ec94b6d862940147e66c1a1",
            "369666ae6dd24c42ba7b2723cb594712",
            "6e81d9d7539f4b56be659609c1e1d1f0",
            "4e0c957217174cffa312f44802cbb169",
            "8aaf8f19965943d1b74709fec1747373",
            "71a72434dd294c9da2404a4affe846ba",
            "252e45fde7174eb99afb4b6a8942d3ed",
            "040f2edef14d4256b34ec45d824b49d2",
            "82209229a54a42dd930ca8aa30454156",
            "00d55e9ae26f473fad57080c5db44072"
          ]
        },
        "id": "Bsa7Q-DoNWBk",
        "outputId": "952edda3-4cf3-445f-82fe-5e8a975bb560"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/56 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef19a27b3ec341079824968a9eb360ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/447 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fb2fb9864894984be397f293b2da32d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "\n",
        "# Build index / generate embeddings using OpenAI embedding model\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    embed_model=OpenAIEmbedding(model=\"text-embedding-3-small\"),\n",
        "    transformations=[SentenceSplitter(chunk_size=512, chunk_overlap=128)],\n",
        "    show_progress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DoUxd8KK--Q"
      },
      "source": [
        "# Query Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bUaNH97dEfh9"
      },
      "outputs": [],
      "source": [
        "# Define a query engine that is responsible for retrieving related pieces of text,\n",
        "# and using a LLM to formulate the final answer.\n",
        "\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "\n",
        "llm = GoogleGenAI(model=\"models/gemini-2.5-flash\", temperature=1)\n",
        "\n",
        "query_engine = index.as_query_engine(llm=llm, similarity_top_k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "KHK4V_GRR6ZG",
        "outputId": "9fac6cbd-f03b-4d91-8666-0e9e331bacf6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "A query engine can be set up in several ways:\n\n1.  **From an existing index**: The simplest method is to create a query engine directly from an index using `index.as_query_engine()`.\n2.  **For SQL tables**: If you know the specific tables you want to query, you can use `NLSQLTableQueryEngine` by providing an `SQLDatabase` object and a list of table names.\n3.  **For unknown tables (Table Index)**: When the tables are not known beforehand or the schema is too large, you can build an `ObjectIndex` (e.g., a `VectorStoreIndex` of `SQLTableSchema` objects) and then construct a `SQLTableRetrieverQueryEngine` using a retriever from this object index and the `SQLDatabase`.\n4.  **With custom stages (RetrieverQueryEngine)**: For granular control, you can assemble a `RetrieverQueryEngine` by configuring its components: a `retriever` (e.g., `VectorIndexRetriever`), a `response_synthesizer`, and optional `node_postprocessors` like `SimilarityPostprocessor`.\n5.  **For multi-document queries (SubQuestionQueryEngine)**: To handle queries across multiple data sources or documents, you can define an index for each source, wrap them with `QueryEngineTool` objects, and then create a `SubQuestionQueryEngine` using these tools."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  3.817213773727417\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "response = query_engine.query(\"How to setup a query engine in code?\")\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "display(Markdown(response.response))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "S-BmyTBbNd9y",
        "outputId": "12769b7e-f37e-417d-fa20-1e31a207fa2d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To set up an agent in code, begin by importing the necessary components such as `ReActAgent`, your chosen Large Language Model (LLM) like `OpenAI`, and `FunctionTool`. Ensure environment variables are loaded if needed.\n\nNext, define the tools the agent will use. These are typically Python functions, like those for multiplication or addition, that are then wrapped into `FunctionTool` objects. The docstrings of these functions serve as metadata, informing the agent about each tool's purpose.\n\nAfter defining tools, initialize your LLM. For example, you can use `OpenAI(model=\"gpt-3.5-turbo\", temperature=0)`. Other models accessible via API or local models like Mixtral via Ollama can also be used.\n\nFinally, initialize the agent itself. A `ReActAgent` can be created by providing it with an array of the defined tools and the initialized LLM, optionally setting `verbose=True` to observe its internal process."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  3.2998409271240234\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "response = query_engine.query(\"How to setup an agent in code?\")\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "display(Markdown(response.response))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_55vnPoSlID"
      },
      "source": [
        "# Setup Long Context Caching\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBSZTxjfSlID"
      },
      "source": [
        "For this section, we will be using the Gemini API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GgY1ySml4wci"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dep30SSV4wYR",
        "outputId": "2c99f82f-e1e0-4f09-b90e-aa115bf2f352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents saved to llama_index_contents.txt\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def create_text_file(input_file: str, output_file: str) -> None:\n",
        "    with open(input_file, \"r\") as f, open(output_file, \"w\") as out:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            out.write(data[\"content\"] + \"\\n\\n\")  # Add two newlines between documents\n",
        "\n",
        "    print(f\"Contents saved to {output_file}\")\n",
        "\n",
        "\n",
        "create_text_file(\"llama_index_150k.jsonl\", \"llama_index_contents.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FEivUijQ5CEq"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# Update the cache's time-to-live (ttl)\n",
        "\n",
        "ttl = f\"{int(datetime.timedelta(minutes=10).total_seconds())}s\"\n",
        "\n",
        "document = client.files.upload(file=\"llama_index_contents.txt\")\n",
        "\n",
        "model_name = \"models/gemini-2.0-flash-001\"\n",
        "\n",
        "cache = client.caches.create(\n",
        "    model=model_name,\n",
        "    config=types.CreateCachedContentConfig(\n",
        "        contents=[document],\n",
        "        system_instruction=\"You answer questions about the LlamaIndex framework.\",\n",
        "        ttl=ttl,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# # To Update the cache\n",
        "\n",
        "# # Alternatively, you update the expire_time directly\n",
        "# # Update the expire_time directly in valid RFC 3339 format (UTC with a \"Z\" suffix)\n",
        "\n",
        "# expire_time = (\n",
        "#     (\n",
        "#         datetime.datetime.now(datetime.timezone.utc)\n",
        "#         + datetime.timedelta(minutes=15)\n",
        "#     )\n",
        "#     .isoformat()\n",
        "#     .replace(\"+00:00\", \"Z\")\n",
        "# )\n",
        "\n",
        "# client.caches.update(\n",
        "#              name=cache.name,\n",
        "#             config=types.UpdateCachedContentConfig(expire_time=expire_time),\n",
        "# )\n",
        "\n",
        "# # To delete cache\n",
        "\n",
        "# client.caches.delete(name=cache.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HHyk7MDr5CAk",
        "outputId": "9b4a3786-2044-4ed2-925e-383d7b5f2979"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LlamaParse is a state-of-the-art document parsing solution developed by the LlamaIndex team. It excels at accurately extracting text and data from complex documents, including PDFs with intricate layouts like tables and multi-column text.\n\nHere's a detailed explanation and setup guide:\n\n**What is LlamaParse?**\n\n*   **Document Parsing Excellence:** LlamaParse is designed to overcome the challenges of parsing documents, especially PDFs. It handles complex layouts, tables, and other formatting intricacies to provide a clean and structured representation of your document's content.\n\n*   **Powered by LlamaCloud:** LlamaParse is offered as part of LlamaCloud, an end-to-end managed service for data parsing, ingestion, indexing, and retrieval. This allows for production-quality data extraction.\n\n*   **Self-Serve API:** Besides being part of LlamaCloud, LlamaParse is also available as a self-serve API, offering flexibility for different use cases.\n\n**How to Set Up LlamaParse**\n\nThere are two primary ways to set up and use LlamaParse: through LlamaCloud or as a self-serve API.\n\n**1. Using LlamaCloud (Managed Service)**\n\n   *   **Sign Up:** Register for a LlamaCloud account at [https://cloud.llamaindex.ai/](https://cloud.llamaindex.ai/).\n   *   **API Key:** Upon signing up, you'll receive a LlamaCloud API key. Store this key securely.\n   *   **Integration:**  Use the LlamaCloud API key to access LlamaParse within the LlamaIndex framework.\n\n**2. Using the Self-Serve API**\n\n   *   **Sign Up:**  Register for a LlamaCloud account at [https://cloud.llamaindex.ai/](https://cloud.llamaindex.ai/). This is needed to obtain an API Key.\n   *   **API Key:** Store the API key.\n   *   **Install `llama-parse`:** Make sure you have the `llama-parse` python package installed.\n\n        ```bash\n        pip install llama-parse\n        ```\n\n   *   **Code Example:** Use the `LlamaParse` class directly in your code:\n\n        ```python\n        from llama_parse import LlamaParse\n\n        # Initialize LlamaParse with your LlamaCloud API key\n        parser = LlamaParse(api_key=\"YOUR_LLAMA_CLOUD_API_KEY\", result_type=\"markdown\")\n\n        # Load data from a PDF file\n        documents = parser.load_data(\"./path/to/your/document.pdf\")\n\n        # The documents variable now contains the parsed content in Markdown format.\n        ```\n\n**Important Considerations:**\n\n*   **API Key Security:** Protect your LlamaCloud API key. Do not expose it in public repositories or client-side code. Store it as an environment variable.\n*   **Free Usage:** LlamaCloud offers a free tier that allows parsing up to 1000 pages per day. For higher usage, you may need to add a credit card to your account.\n*   **Asynchronous Parsing:**  Parsing large documents can take time. LlamaParse might operate asynchronously, meaning you'll submit the document and retrieve the results later.\n\n**Example in context of general LlamaIndex RAG pipeline:**\n\n```python\nfrom llama_index.core import VectorStoreIndex\nfrom llama_index.core import SimpleDirectoryReader, Settings\nfrom llama_index.llms.openai import OpenAI\nfrom llama_parse import LlamaParse\n\n# 1. Configure LLM\nSettings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n\n# 2. Load documents with LlamaParse\ndocuments = LlamaParse(result_type=\"markdown\").load_data(\n    \"./data/2023_canadian_budget.pdf\"\n)\n\n# 3. Build index\nindex = VectorStoreIndex.from_documents(documents)\n\n# 4. Setup query engine\nquery_engine = index.as_query_engine()\n\n# 5. Query index\nresponse = query_engine.query(\n    \"How much exactly was allocated to a tax credit to promote investment in green technologies in the 2023 Canadian federal budget?\"\n)\nprint(response)\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  8.745552778244019\n"
          ]
        }
      ],
      "source": [
        "# Use the cache for generation\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=\"What is LlamaParse, How to setup? Explain detail\",\n",
        "    config=types.GenerateContentConfig(cached_content=cache.name),\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "display(Markdown(response.text))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbyW-W7P5B8w",
        "outputId": "ce347a94-27c4-473c-a6d8-e322c061cacc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerateContentResponseUsageMetadata(\n",
              "  cache_tokens_details=[\n",
              "    ModalityTokenCount(\n",
              "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
              "      token_count=212635\n",
              "    ),\n",
              "  ],\n",
              "  cached_content_token_count=212635,\n",
              "  candidates_token_count=908,\n",
              "  candidates_tokens_details=[\n",
              "    ModalityTokenCount(\n",
              "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
              "      token_count=908\n",
              "    ),\n",
              "  ],\n",
              "  prompt_token_count=212646,\n",
              "  prompt_tokens_details=[\n",
              "    ModalityTokenCount(\n",
              "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
              "      token_count=212646\n",
              "    ),\n",
              "  ],\n",
              "  total_token_count=213554\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "response.usage_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skIXhzGyLixv"
      },
      "source": [
        "## First token response time in Straming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "dIIspB7d4v3-",
        "outputId": "ccc6fe6b-acad-4147-e6f4-5b48e39fbe1c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  3.675197124481201\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=\"How to setup a Router query engine?\",\n",
        "    config=types.GenerateContentConfig(cached_content=cache.name,max_output_tokens=1),\n",
        ")\n",
        "end = time.time()\n",
        "display(Markdown(response.text))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "U3PKSPhof079"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef19a27b3ec341079824968a9eb360ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f5d0529325f48cab8a951dfe6859e75",
              "IPY_MODEL_22a620bac4e44273a6b6d274d49feba4",
              "IPY_MODEL_9683e2507a84488d9d7a509eed8c7c81"
            ],
            "layout": "IPY_MODEL_3c43c9ce47a745b3ae4a73373a1a8198"
          }
        },
        "1f5d0529325f48cab8a951dfe6859e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fc89c07b44343cd939ec5aeb4b417b2",
            "placeholder": "​",
            "style": "IPY_MODEL_1c31b247667043edb97292773264e46e",
            "value": "Parsing nodes: 100%"
          }
        },
        "22a620bac4e44273a6b6d274d49feba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5caef618fbe415f966f88613623f91a",
            "max": 56,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7295a321785440aa8d33ffb9cd20f8e",
            "value": 56
          }
        },
        "9683e2507a84488d9d7a509eed8c7c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e668fd18f1747e7a7094cffd90a51e0",
            "placeholder": "​",
            "style": "IPY_MODEL_5c089e3b178a42eea20ef58fce9071b2",
            "value": " 56/56 [00:08&lt;00:00, 10.64it/s]"
          }
        },
        "3c43c9ce47a745b3ae4a73373a1a8198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc89c07b44343cd939ec5aeb4b417b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c31b247667043edb97292773264e46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5caef618fbe415f966f88613623f91a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7295a321785440aa8d33ffb9cd20f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e668fd18f1747e7a7094cffd90a51e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c089e3b178a42eea20ef58fce9071b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fb2fb9864894984be397f293b2da32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ce6ea118ec94b6d862940147e66c1a1",
              "IPY_MODEL_369666ae6dd24c42ba7b2723cb594712",
              "IPY_MODEL_6e81d9d7539f4b56be659609c1e1d1f0"
            ],
            "layout": "IPY_MODEL_4e0c957217174cffa312f44802cbb169"
          }
        },
        "4ce6ea118ec94b6d862940147e66c1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aaf8f19965943d1b74709fec1747373",
            "placeholder": "​",
            "style": "IPY_MODEL_71a72434dd294c9da2404a4affe846ba",
            "value": "Generating embeddings: 100%"
          }
        },
        "369666ae6dd24c42ba7b2723cb594712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_252e45fde7174eb99afb4b6a8942d3ed",
            "max": 447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_040f2edef14d4256b34ec45d824b49d2",
            "value": 447
          }
        },
        "6e81d9d7539f4b56be659609c1e1d1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82209229a54a42dd930ca8aa30454156",
            "placeholder": "​",
            "style": "IPY_MODEL_00d55e9ae26f473fad57080c5db44072",
            "value": " 447/447 [00:06&lt;00:00, 77.74it/s]"
          }
        },
        "4e0c957217174cffa312f44802cbb169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aaf8f19965943d1b74709fec1747373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a72434dd294c9da2404a4affe846ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "252e45fde7174eb99afb4b6a8942d3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "040f2edef14d4256b34ec45d824b49d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82209229a54a42dd930ca8aa30454156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00d55e9ae26f473fad57080c5db44072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}