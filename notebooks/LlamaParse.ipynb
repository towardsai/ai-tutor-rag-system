{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3iSJpxmEML0w",
        "outputId": "295b46e3-6957-4021-c867-ff452d7e2038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index==0.14.0 llama-parse==0.6.54 jedi==0.19.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n9OKejSAM1Kj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# API access to llama-cloud\n",
        "# os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-\"\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = userdata.get('LlamaParse_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b7b5debe7dbf4211a8faccf90fba7a47",
            "2793bc459e14420dbc555ce31d56ef9b",
            "6c927f6fc5874d0599a6fb963c73a107",
            "2be7c38376c94fda854f24eecd926d1b",
            "41a15f72db4f40e48c39147df220ce57",
            "0d000b56f54542a38ed60d3d3e1a8d9a",
            "d2bbaebabc084bbb9a0955ea689790eb",
            "290b8a1dbd3b40608880469042530823",
            "15e5111cce1c47eb9da24abeacea41cf",
            "9bd469ff25c54c67b243da5464fea477",
            "96db970dbc3e45cbb741400c8d334431"
          ]
        },
        "id": "Xs5WjC01NCiy",
        "outputId": "4613bdc4-166b-48b4-d480-bd8dfd3d0574"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "research_papers_llamaparse.zip:   0%|          | 0.00/13.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7b5debe7dbf4211a8faccf90fba7a47"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Downloading Research paper dataset from HuggingFace Hub\n",
        "from huggingface_hub import hf_hub_download\n",
        "file_path = hf_hub_download(repo_id=\"jaiganesan/ai_tutor_knowledge\", filename=\"research_papers_llamaparse.zip\",repo_type=\"dataset\",local_dir=\"/content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRNqM8cIPQC_",
        "outputId": "34c7ed9b-ead5-4b8f-b59b-a362970de6ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  research_papers_llamaparse.zip\n",
            "   creating: research_papers_llamaparse/\n",
            "  inflating: research_papers_llamaparse/2106.09685v2.pdf  \n",
            "  inflating: research_papers_llamaparse/2404.19756v2.pdf  \n",
            "  inflating: research_papers_llamaparse/2405.07437v2.pdf  \n"
          ]
        }
      ],
      "source": [
        "!unzip research_papers_llamaparse.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itMgf7Dsptw4"
      },
      "source": [
        "## Parse directory to LlamaParse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "uN0oFRsGTcIF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LlamaParse Implemetation\n",
        "from llama_parse import LlamaParse\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "#Parser\n",
        "parser = LlamaParse(\n",
        "    result_type=\"markdown\",\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "vNInOZ3rbPSX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir=\"/content/research_papers_llamaparse\"\n",
        "\n",
        "file_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.lower().endswith(\".pdf\")]\n",
        "\n",
        "documents = await parser.aparse(file_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qv_pyynbWXi",
        "outputId": "36b065fd-75ba-4431-ad2d-ddee8f03f822"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGetting job results:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id 5fbc6535-92d9-4a86-ba91-901d20963605\n",
            "Started parsing the file under job_id 7fe83c73-8350-42ad-9a3b-7fe9d651bdbd\n",
            "Started parsing the file under job_id 87134a5e-9f81-4576-b6fd-8d7afac829b1\n",
            "..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Getting job results:  67%|██████▋   | 2/3 [01:16<00:36, 36.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Getting job results: 100%|██████████| 3/3 [02:48<00:00, 56.21s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents[0].pages[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9AE-vHW20B0",
        "outputId": "364c24cd-0d17-4c6d-8cef-5e4f745fd289"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arXiv:2405.07437v2 [cs.CL] 3 Jul 2024\n",
            "\n",
            "\n",
            "                 Evaluation of Retrieval-Augmented Generation:\n",
            "                                    A Survey\n",
            "\n",
            "Hao Yu1,2, Aoran Gan3, Kai Zhang3, Shiwei Tong1†, Qi Liu3, and Zhaofeng Liu1\n",
            "\n",
            "1           Tencent Company\n",
            "2           McGill University\n",
            "          3 State Key Laboratory of Cognitive Intelligence,\n",
            "            University of Science and Technology of China\n",
            "                             hao.yu2@mail.mcgill.ca\n",
            "                              gar@mail.ustc.edu.cn\n",
            "          {shiweitong†,zhaofengliu}@tencent.com\n",
            "                        {kkzhang08,qiliuql}@ustc.edu.cn\n",
            "\n",
            "Abstract. Retrieval-Augmented Generation (RAG) has recently gained traction\n",
            "  in natural language processing. Numerous studies and real-world applications\n",
            "are leveraging its ability to enhance generative models through external informa-\n",
            " tion retrieval. Evaluating these RAG systems, however, poses unique challenges\n",
            "  due to their hybrid structure and reliance on dynamic knowledge sources. To\n",
            " better understand these challenges, we conduct A Unified Evaluation Process of\n",
            "  RAG (Auepora) and aim to provide a comprehensive overview of the evaluation\n",
            "  and benchmarks of RAG systems. Specifically, we examine and compare several\n",
            "quantifiable metrics of the Retrieval and Generation components, such as rele-\n",
            "  vance, accuracy, and faithfulness, within the current RAG benchmarks, encom-\n",
            "passing the possible output and ground truth pairs. We then analyze the various\n",
            "datasets and metrics, discuss the limitations of current benchmarks, and suggest\n",
            "potential directions to advance the field of RAG benchmarks.\n",
            "\n",
            "\n",
            "1  Introduction\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) [34] efficiently enhances the performance of\n",
            "generative language models through integrating information retrieval techniques. It ad-\n",
            "dresses a critical challenge faced by standalone generative language models: the ten-\n",
            "dency to produce responses that, while plausible, may not be grounded in facts. By\n",
            "retrieving relevant information from external sources, RAG significantly reduces the\n",
            "incidence of hallucinations [23] or factually incorrect outputs, thereby improving the\n",
            "content’s reliability and richness. [73] This fusion of retrieval and generation capabil-\n",
            "ities enables the creation of responses that are not only contextually appropriate but\n",
            "also informed by the most current and accurate information available, making RAG a\n",
            "development in the pursuit of more intelligent and versatile language models [73,64].\n",
            "\n",
            "†  Corresponding Author\n",
            "   Paper Homepage: https://github.com/YHPeter/Awesome-RAG-Evaluation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCfzTVX0pqhs"
      },
      "source": [
        "## LlamaParse JSON Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBb4VjgPPiWq",
        "outputId": "5d5c5535-920b-4d4b-b568-57376b8beedd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rParsing files:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id b735e016-19e1-49c7-8151-538e54d69953\n",
            "Started parsing the file under job_id 17ddb89f-beb4-4b20-b226-2006a413afc4\n",
            "Started parsing the file under job_id 0766ba5f-4802-4f45-9307-9adb854ed6a7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parsing files: 100%|██████████| 3/3 [00:18<00:00,  6.04s/it]\n"
          ]
        }
      ],
      "source": [
        "# Using LlamaParse in JSON Mode for PDF Reading\n",
        "\n",
        "import glob\n",
        "pdf_files = glob.glob(\"/content/research_papers_llamaparse/*.pdf\")\n",
        "\n",
        "parser = LlamaParse(verbose=True)\n",
        "\n",
        "json_objs=parser.get_json_result(pdf_files)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_objs[0]['pages'][1]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "WUwCG9Xb4WoY",
        "outputId": "a06f3a33-e63b-4ba5-cb4b-52170134eade"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2           Hao Yu, Aoran Gan, Kai Zhang, Shiwei Tong†, Qi Liu, and Zhaofeng Liu\\n\\n   Numerous studies of RAG systems have emerged from various perspectives since\\nthe advent of Large Language Models (LLMs) [55,45,59,42,41,69,16]. The RAG sys-\\ntem comprises two primary components: Retrieval and Generation. The retrieval com-\\nponent aims to extract relevant information from various external knowledge sources.\\nIt involves two main phases, indexing and searching. Indexing organizes documents to\\nfacilitate efficient retrieval, using either inverted indexes for sparse retrieval or dense\\nvector encoding for dense retrieval [16,12,28]. The searching component utilizes these\\nindexes to fetch relevant documents on the user’s query, often incorporating the op-\\ntional rerankers [4,39,6,52] to refine the ranking of the retrieved documents. The gener-\\nation component utilizes the retrieved content and question query to formulate coherent\\nand contextually relevant responses with the prompting and inferencing phases. As the\\n“Emerging” ability [59] of LLMs and the breakthrough in aligning human commands\\n[42], LLMs are the best performance choices model for the generation stage. Prompt-\\ning methods like Chain of Thought (CoT) [60], Tree of Thgouht [65], Rephrase and\\nRespond (RaR) [8] guide better generation results. In the inferencing step, LLMs inter-\\npret the prompted input to generate accurate and in-depth responses that align with the\\nquery’s intent and integrate the extracted information [35,9] without further finetuning,\\nsuch as fully finetuning [16,1,67,68] or LoRA [21]. Appendix A details the complete\\nRAG structure. Figure 1 illustrates the structure of the RAG systems as mentioned.\\n\\n                          Retrieval                   Generation            Ground Truth\\n                                       II. Search     III. Prompting\\n            Web Search Engine  20                      Query        20\\n   Query    BM25                       Relevant    Relevant Docs    Complete\\n                       Documents                   System Prompt     Prompt\\n            KNN/ANN    with Score\\n                                                   Prompt Skills\\n\\n                                                                            Docs Candidates\\n                                       IDF            Large Language Mode\\n            Wikipedia                  Vector         Response              Sample Response\\n            HF Dataset                 ES             Post\\n                                       Database        rocessing.               Label\\n                                                                      Output\\n                                       I. Indexing    IV. Inferencing\\n\\nFig. 1: The structure of the RAG system with retrieval and generation components and\\ncorresponding four phrases: indexing, search, prompting and inferencing. The pairs of\\n“Evaluable Outputs” (EOs) and “Ground Truths” (GTs) are highlighted in read frame\\nand green frame, with brown dashed arrows.\\n\\n   The importance of evaluating RAG is increasing in parallel with the advancement\\nof RAG-specific methodologies. On the one hand, RAG is a complex system intricately\\ntied to specific requirements and language models, resulting in various evaluation meth-\\nods, indicators, and tools, particularly given the black-box LLM generation. Evaluating\\nRAG systems involves specific components and the complexity of the overall system\\nassessment. On the other hand, the complexity of RAG systems is further compounded'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "fN075z18fAHI",
        "outputId": "34149841-74cf-4cad-e3e3-af238f18b449"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                      Evaluation of Retrieval-Augmented Generation: A Survey                            5\\n\\n                            Result  Query               Ground Truth\\n Retrieval     Relevant Docs        A Docs Candidates                     Relevant Docs  Query              Relevance\\n                                        >                                 Relevant Docs  Docs Candidates        Accuracy\\n               Response                               Sample Response     Response  Query                      Relevance\\n Generation                 Output                         Label          Response  Relevant Docs           Faithfulness\\n                                                                          Response  Sample Response          Correctness\\n Additional Requirements                     Latency, Noise Robustness, Negative Rejection, Diversity,..\\n\\n                                         Fig. 2: The Target modular of the Auepora.\\n\\n3.1  Evaluation Target (What to Evaluate?)\\n\\nThe combination of EOs and GTs in the RAG system can generate all possible targets,\\nwhich is the fundamental concept of the Auepora (as shown in Figure 1). Once iden-\\ntified, these targets can be defined based on a specific pair of EOs or EO with GT, as\\nillustrated in Figure 2, and used to analyze all aspects of current RAG benchmarks.\\n\\nRetrieval                                       The EOs are the relevant documents for evaluating the retrieval component\\ndepending on the query. Then we can construct two pairwise relationships for the re-\\ntrieval component, which are Relevant Documents ↔ Query, Relevant Documents ↔\\nDocuments Candidates.\\n\\n  -  Relevance (Relevant Documents ↔ Query) evaluates how well the retrieved docu-\\n     ments match the information needed expressed in the query. It measures the preci-\\n     sion and specificity of the retrieval process.\\n  -  Accuracy (Relevant Documents ↔ Documents Candidates) assesses how accurate\\n     the retrieved documents are in comparison to a set of candidate documents. It is\\n     a measure of the system’s ability to identify and score relevant documents higher\\n     than less relevant or irrelevant ones.\\n\\nGeneration                                        The similar pairwise relations for the generation components are listed\\nbelow. The EOs are the generated text and phrased structured content. Then we need to\\ncompare these EOs with the provided GTs and labels.\\n\\n  -  Relevance (Response ↔ Query) measures how well the generated response aligns\\n     with the intent and content of the initial query. It ensures that the response is related\\n     to the query topic and meets the query’s specific requirements.\\n  -  Faithfulness (Response ↔ Relevant Documents) evaluates if the generated re-\\n     sponse accurately reflects the information contained within the relevant documents\\n     and measures the consistency between generated content and the source documents.\\n  -  Correctness (Response ↔ Sample Response) Similar to the accuracy in the re-\\n     trieval component, this measures the accuracy of the generated response against a\\n     sample response, which serves as a ground truth. It checks if the response is correct\\n     in terms of factual information and appropriate in the context of the query.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "json_objs[0]['pages'][4]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEnTFCn2pgB7",
        "outputId": "126d28d5-1c71-4d06-dc2a-3d4893af3788"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'table',\n",
              " 'rows': [['Category',\n",
              "   'Framework',\n",
              "   'Time',\n",
              "   'Raw Targets',\n",
              "   'Retrieval',\n",
              "   'Generation'],\n",
              "  ['Tool',\n",
              "   'TruEra RAG Triad [54]',\n",
              "   '2023.10',\n",
              "   'Answer Relevance',\n",
              "   'LLM as a Judge',\n",
              "   'LLM as a Judge'],\n",
              "  ['Tool',\n",
              "   'LangChain Bench. [32]',\n",
              "   '2023.11',\n",
              "   'Faithfulness',\n",
              "   'Accuracy',\n",
              "   'LLM as a Judge'],\n",
              "  ['Tool',\n",
              "   'Databricks Eval [33]',\n",
              "   '2023.12',\n",
              "   'Readability',\n",
              "   '-',\n",
              "   'LLM as a Judge'],\n",
              "  ['Benchmark',\n",
              "   'RAGAs [14]',\n",
              "   '2023.09',\n",
              "   'Answer Relevance',\n",
              "   'LLM as a Judge',\n",
              "   'LLM as a Judge'],\n",
              "  ['Benchmark',\n",
              "   'RECALL [38]',\n",
              "   '2023.11',\n",
              "   'Response Quality',\n",
              "   '-',\n",
              "   'BLEU, ROUGE-L'],\n",
              "  ['Benchmark',\n",
              "   'ARES [49]',\n",
              "   '2023.11',\n",
              "   'Answer Faithfulness',\n",
              "   'LLM + Classifier',\n",
              "   'LLM + Classifier'],\n",
              "  ['Benchmark', 'RGB [6]', '2023.12', 'Noise Robustness', '-', 'Accuracy'],\n",
              "  ['Benchmark',\n",
              "   'MultiHop-RAG [52]',\n",
              "   '2024.01',\n",
              "   'Retrieval Quality',\n",
              "   'MAP, MRR, Hit@K',\n",
              "   'LLM as a Judge'],\n",
              "  ['Benchmark',\n",
              "   'CRUD-RAG [39]',\n",
              "   '2024.02',\n",
              "   'CREATE, READ',\n",
              "   '-',\n",
              "   'ROUGE, BLEU'],\n",
              "  ['Benchmark', 'MedRAG [61]', '2024.02', 'Accuracy', '-', 'Accuracy'],\n",
              "  ['Benchmark',\n",
              "   'FeB4RAG [57]',\n",
              "   '2024.02',\n",
              "   'Correctness',\n",
              "   '-',\n",
              "   'Human Evaluation'],\n",
              "  ['Benchmark', 'CDQA [62]', '2024.03', 'Accuracy', '-', 'F1'],\n",
              "  ['Benchmark', 'DomainRAG [58]', '2024.06', 'Faithfulness', '-', 'Rouge-L'],\n",
              "  ['Benchmark',\n",
              "   'ReEval [66]',\n",
              "   '2024.06',\n",
              "   'Hallucination',\n",
              "   '-',\n",
              "   'LLM as a Judge'],\n",
              "  ['Research', 'FiD-Light [20]', '2023.07', 'Latency', '-', '-'],\n",
              "  ['Research',\n",
              "   'Diversity Reranker [4]',\n",
              "   '2023.08',\n",
              "   'Diversity',\n",
              "   'Cosine Distance',\n",
              "   '-']],\n",
              " 'md': '| Category  | Framework               | Time    | Raw Targets         | Retrieval        | Generation       |\\n| --------- | ----------------------- | ------- | ------------------- | ---------------- | ---------------- |\\n| Tool      | TruEra RAG Triad \\\\[54]  | 2023.10 | Answer Relevance    | LLM as a Judge   | LLM as a Judge   |\\n| Tool      | LangChain Bench. \\\\[32]  | 2023.11 | Faithfulness        | Accuracy         | LLM as a Judge   |\\n| Tool      | Databricks Eval \\\\[33]   | 2023.12 | Readability         | -                | LLM as a Judge   |\\n| Benchmark | RAGAs \\\\[14]             | 2023.09 | Answer Relevance    | LLM as a Judge   | LLM as a Judge   |\\n| Benchmark | RECALL \\\\[38]            | 2023.11 | Response Quality    | -                | BLEU, ROUGE-L    |\\n| Benchmark | ARES \\\\[49]              | 2023.11 | Answer Faithfulness | LLM + Classifier | LLM + Classifier |\\n| Benchmark | RGB \\\\[6]                | 2023.12 | Noise Robustness    | -                | Accuracy         |\\n| Benchmark | MultiHop-RAG \\\\[52]      | 2024.01 | Retrieval Quality   | MAP, MRR, Hit\\\\@K | LLM as a Judge   |\\n| Benchmark | CRUD-RAG \\\\[39]          | 2024.02 | CREATE, READ        | -                | ROUGE, BLEU      |\\n| Benchmark | MedRAG \\\\[61]            | 2024.02 | Accuracy            | -                | Accuracy         |\\n| Benchmark | FeB4RAG \\\\[57]           | 2024.02 | Correctness         | -                | Human Evaluation |\\n| Benchmark | CDQA \\\\[62]              | 2024.03 | Accuracy            | -                | F1               |\\n| Benchmark | DomainRAG \\\\[58]         | 2024.06 | Faithfulness        | -                | Rouge-L          |\\n| Benchmark | ReEval \\\\[66]            | 2024.06 | Hallucination       | -                | LLM as a Judge   |\\n| Research  | FiD-Light \\\\[20]         | 2023.07 | Latency             | -                | -                |\\n| Research  | Diversity Reranker \\\\[4] | 2023.08 | Diversity           | Cosine Distance  | -                |',\n",
              " 'isPerfectTable': True,\n",
              " 'csv': '\"Category\",\"Framework\",\"Time\",\"Raw Targets\",\"Retrieval\",\"Generation\"\\n\"Tool\",\"TruEra RAG Triad [54]\",\"2023.10\",\"Answer Relevance\",\"LLM as a Judge\",\"LLM as a Judge\"\\n\"Tool\",\"LangChain Bench. [32]\",\"2023.11\",\"Faithfulness\",\"Accuracy\",\"LLM as a Judge\"\\n\"Tool\",\"Databricks Eval [33]\",\"2023.12\",\"Readability\",\"-\",\"LLM as a Judge\"\\n\"Benchmark\",\"RAGAs [14]\",\"2023.09\",\"Answer Relevance\",\"LLM as a Judge\",\"LLM as a Judge\"\\n\"Benchmark\",\"RECALL [38]\",\"2023.11\",\"Response Quality\",\"-\",\"BLEU, ROUGE-L\"\\n\"Benchmark\",\"ARES [49]\",\"2023.11\",\"Answer Faithfulness\",\"LLM + Classifier\",\"LLM + Classifier\"\\n\"Benchmark\",\"RGB [6]\",\"2023.12\",\"Noise Robustness\",\"-\",\"Accuracy\"\\n\"Benchmark\",\"MultiHop-RAG [52]\",\"2024.01\",\"Retrieval Quality\",\"MAP, MRR, Hit@K\",\"LLM as a Judge\"\\n\"Benchmark\",\"CRUD-RAG [39]\",\"2024.02\",\"CREATE, READ\",\"-\",\"ROUGE, BLEU\"\\n\"Benchmark\",\"MedRAG [61]\",\"2024.02\",\"Accuracy\",\"-\",\"Accuracy\"\\n\"Benchmark\",\"FeB4RAG [57]\",\"2024.02\",\"Correctness\",\"-\",\"Human Evaluation\"\\n\"Benchmark\",\"CDQA [62]\",\"2024.03\",\"Accuracy\",\"-\",\"F1\"\\n\"Benchmark\",\"DomainRAG [58]\",\"2024.06\",\"Faithfulness\",\"-\",\"Rouge-L\"\\n\"Benchmark\",\"ReEval [66]\",\"2024.06\",\"Hallucination\",\"-\",\"LLM as a Judge\"\\n\"Research\",\"FiD-Light [20]\",\"2023.07\",\"Latency\",\"-\",\"-\"\\n\"Research\",\"Diversity Reranker [4]\",\"2023.08\",\"Diversity\",\"Cosine Distance\",\"-\"',\n",
              " 'bBox': {'x': 134.76, 'y': 115.84, 'w': 345.83, 'h': 541.22}}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Table information\n",
        "json_objs[0]['pages'][5]['items'][5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CkkzplqfxnGr"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7b5debe7dbf4211a8faccf90fba7a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2793bc459e14420dbc555ce31d56ef9b",
              "IPY_MODEL_6c927f6fc5874d0599a6fb963c73a107",
              "IPY_MODEL_2be7c38376c94fda854f24eecd926d1b"
            ],
            "layout": "IPY_MODEL_41a15f72db4f40e48c39147df220ce57"
          }
        },
        "2793bc459e14420dbc555ce31d56ef9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d000b56f54542a38ed60d3d3e1a8d9a",
            "placeholder": "​",
            "style": "IPY_MODEL_d2bbaebabc084bbb9a0955ea689790eb",
            "value": "research_papers_llamaparse.zip: 100%"
          }
        },
        "6c927f6fc5874d0599a6fb963c73a107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_290b8a1dbd3b40608880469042530823",
            "max": 13584308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15e5111cce1c47eb9da24abeacea41cf",
            "value": 13584308
          }
        },
        "2be7c38376c94fda854f24eecd926d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bd469ff25c54c67b243da5464fea477",
            "placeholder": "​",
            "style": "IPY_MODEL_96db970dbc3e45cbb741400c8d334431",
            "value": " 13.6M/13.6M [00:01&lt;00:00, 12.1MB/s]"
          }
        },
        "41a15f72db4f40e48c39147df220ce57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d000b56f54542a38ed60d3d3e1a8d9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bbaebabc084bbb9a0955ea689790eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "290b8a1dbd3b40608880469042530823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e5111cce1c47eb9da24abeacea41cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bd469ff25c54c67b243da5464fea477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96db970dbc3e45cbb741400c8d334431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}