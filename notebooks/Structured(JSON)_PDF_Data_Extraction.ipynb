{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCSQ-KFvNeMj"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/towardsai/ai-tutor-rag-system/blob/main/notebooks/Structured(JSON)_PDF_Data_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rCndQqynkNiQ",
    "outputId": "1555c9b8-827d-4185-e2fc-1ae2e2c73faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/310.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m307.2/310.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q openai==1.107.0 pypdf==6.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdAwk6gTsDA3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Set the \"OPENAI_API_KEY\" in the Python environment. Will be used by OpenAI client later.\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"[OPENAI_API_KEY]\"\n",
    "\n",
    "from google.colab import userdata\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kk_QGIJLT8qY"
   },
   "source": [
    "### OpenAI Structured Output without `response_format`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_F_PrQCT6lp"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "gaCYqKDrT6Va",
    "outputId": "563b9375-2f1c-4831-f467-c9f3deea34c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Top10BestSellingBooks\": [\n",
      "    {\n",
      "      \"title\": \"Don Quixote\",\n",
      "      \"author\": \"Miguel de Cervantes\",\n",
      "      \"yearPublished\": \"1605\",\n",
      "      \"summary\": \"A delusional nobleman, inspired by chivalric romances, embarks on misguided adventures with his loyal squire Sancho Panza, satirizing heroism and exploring reality versus illusion.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A Tale of Two Cities\",\n",
      "      \"author\": \"Charles Dickens\",\n",
      "      \"yearPublished\": \"1859\",\n",
      "      \"summary\": \"Set against the French Revolution, the fates of several characters intertwine across London and Paris, highlighting sacrifice, injustice, and resurrection.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The Lord of the Rings\",\n",
      "      \"author\": \"J. R. R. Tolkien\",\n",
      "      \"yearPublished\": \"1954\",\n",
      "      \"summary\": \"A fellowship undertakes a perilous quest to destroy a powerful ring and defeat the Dark Lord Sauron, reshaping the fate of Middle-earth.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The Little Prince\",\n",
      "      \"author\": \"Antoine de Saint-Exupéry\",\n",
      "      \"yearPublished\": \"1943\",\n",
      "      \"summary\": \"A pilot stranded in the desert meets a young prince from another planet, reflecting on love, loss, and the essence of human connections.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Harry Potter and the Philosopher's Stone\",\n",
      "      \"author\": \"J. K. Rowling\",\n",
      "      \"yearPublished\": \"1997\",\n",
      "      \"summary\": \"An orphan discovers he is a wizard and begins his education at Hogwarts, uncovering the mystery of a powerful stone and his connection to a dark foe.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"And Then There Were None\",\n",
      "      \"author\": \"Agatha Christie\",\n",
      "      \"yearPublished\": \"1939\",\n",
      "      \"summary\": \"Ten strangers are lured to a remote island and accused of past crimes; one by one they die, as paranoia and guilt mount.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Dream of the Red Chamber\",\n",
      "      \"author\": \"Cao Xueqin\",\n",
      "      \"yearPublished\": \"1791\",\n",
      "      \"summary\": \"An intricate portrait of an aristocratic family's rise and decline in Qing Dynasty China, blending romance, social critique, and spiritual reflection.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The Hobbit\",\n",
      "      \"author\": \"J. R. R. Tolkien\",\n",
      "      \"yearPublished\": \"1937\",\n",
      "      \"summary\": \"Bilbo Baggins is swept into an adventure with dwarves to reclaim their homeland, confronting dragons, trolls, and his own courage.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The Lion, the Witch and the Wardrobe\",\n",
      "      \"author\": \"C. S. Lewis\",\n",
      "      \"yearPublished\": \"1950\",\n",
      "      \"summary\": \"Four siblings enter the magical land of Narnia through a wardrobe and join Aslan to overthrow the White Witch's eternal winter.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The Da Vinci Code\",\n",
      "      \"author\": \"Dan Brown\",\n",
      "      \"yearPublished\": \"2003\",\n",
      "      \"summary\": \"A symbologist and a cryptologist race across Europe to unravel a murder and a conspiracy tied to secret societies and religious history.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant designed to output information exclusively in JSON format. Your response should contain only raw JSON data with no additional text, explanations, or comments. Do not include backticks (`) or any code block delimiters in your response.\n",
    "\n",
    "Always use the key `\"Top10BestSellingBooks\"` when listing top 10 best-selling books. Follow the specified JSON structure below:\n",
    "\n",
    "### JSON Format Example\n",
    "{\n",
    "  \"Top10BestSellingBooks\": [\n",
    "    {\n",
    "      \"title\": \"Book Title\",\n",
    "      \"author\": \"Author Name\",\n",
    "      \"yearPublished\": \"Year\",\n",
    "      \"summary\": \"Brief summary of the book.\"\n",
    "    },\n",
    "    {\n",
    "      \"title\": \"Book Title 2\",\n",
    "      \"author\": \"Author Name 2\",\n",
    "      \"yearPublished\": \"Year\",\n",
    "      \"summary\": \"Brief summary of the book.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "Always respond with clean JSON output that can be directly used with JSON parsers like `json.loads()`.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"Give me the names of the 10 best-selling books, their authors, the year they were published, and a concise summary in JSON format\"\n",
    "\n",
    "# Making the API call\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-5\",\n",
    "  instructions=system_prompt,\n",
    "  input=prompt,\n",
    "  reasoning={\"effort\": \"minimal\"}\n",
    ")\n",
    "print(response.output[1].content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hY1nUQ8QT6Rv",
    "outputId": "80934cce-0a49-4ecf-ff17-804d26b9c0f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'title': 'Don Quixote', 'author': 'Miguel de Cervantes', 'yearPublished': '1605', 'summary': 'A delusional nobleman, inspired by chivalric romances, embarks on misguided adventures with his loyal squire Sancho Panza, satirizing heroism and exploring reality versus illusion.'}\n",
      "-------------------------------------\n",
      "Don Quixote\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result_book = json.loads(response.output[1].content[0].text)\n",
    "\n",
    "print(type(result_book))\n",
    "\n",
    "print(result_book['Top10BestSellingBooks'][0])\n",
    "print(\"-------------------------------------\")\n",
    "print(result_book['Top10BestSellingBooks'][0]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZpYV-q0--QB"
   },
   "source": [
    "## OpenAI Strucutred output (JSON) with `response_format`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iH1CDNr30dtU"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8702bCYi9xpy"
   },
   "outputs": [],
   "source": [
    "prompt = \"Give me the names of the 10 best-selling books, their authors, the year they were published, and a concise summary in JSON format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlCRdRTQ9FNh"
   },
   "outputs": [],
   "source": [
    "# The response format- JSON schema\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from typing import List\n",
    "\n",
    "class Books(BaseModel):\n",
    "    \"\"\"Summary\"\"\"\n",
    "    title: str = Field(..., description=\"Title of the book\")\n",
    "    author: str = Field(..., description=\"Author of the book\")\n",
    "    yearPublished: int = Field(..., description=\"Year the book was published\", alias=\"yearPublished\")\n",
    "    summary: str = Field(..., description=\"Brief summary of the book\")\n",
    "\n",
    "class BookResponseFormatJSON(BaseModel):\n",
    "  Top10BestSellingBooks: List[Books] = Field(..., description=\"List of top 10 best-selling books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwcVCEOExNuL"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant designed to output information exclusively in JSON format.\n",
    "### JSON Format Example\n",
    "{\n",
    "  \"Top10BestSellingBooks\": [\n",
    "    {\n",
    "      \"title\": \"Book Title\",\n",
    "      \"author\": \"Author Name\",\n",
    "      \"yearPublished\": \"Year\",\n",
    "      \"summary\": \"Brief summary of the book.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "kY_AfQvR91Ei",
    "outputId": "f14e23f2-990c-4aed-d5e6-ca932171cfd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top10BestSellingBooks=[Books(title='Don Quixote', author='Miguel de Cervantes', yearPublished=1605, summary='A delusional hidalgo, inspired by chivalric romances, becomes a self-styled knight-errant and embarks on misadventures with his pragmatic squire, Sancho Panza, satirizing heroism and reality.'), Books(title='A Tale of Two Cities', author='Charles Dickens', yearPublished=1859, summary='Set in London and Paris during the French Revolution, the novel follows sacrifices and redemption as lives intersect amid social upheaval, culminating in a famous act of selfless love.'), Books(title='The Lord of the Rings', author='J. R. R. Tolkien', yearPublished=1954, summary='An epic quest to destroy the One Ring pits hobbits and allies against Sauron, exploring friendship, power, and the struggle between good and evil in Middle-earth.'), Books(title='The Little Prince', author='Antoine de Saint-Exupéry', yearPublished=1943, summary='A pilot stranded in the desert meets a boy from another planet; their conversations reflect on love, loss, and the often-misunderstood wisdom of childhood.'), Books(title='Harry Potter and the Philosopher’s Stone', author='J. K. Rowling', yearPublished=1997, summary='An orphan discovers he is a wizard, attends Hogwarts School of Witchcraft and Wizardry, and confronts the dark legacy of Lord Voldemort.'), Books(title='And Then There Were None', author='Agatha Christie', yearPublished=1939, summary='Ten strangers are lured to an isolated island and are killed one by one, a masterclass in mystery plotting built around a sinister nursery rhyme.'), Books(title='Dream of the Red Chamber', author='Cao Xueqin', yearPublished=1791, summary='A sweeping portrait of the decline of an aristocratic Chinese family, intertwining romance, fate, and social critique during the Qing dynasty.'), Books(title='The Hobbit', author='J. R. R. Tolkien', yearPublished=1937, summary='Bilbo Baggins, a reluctant hobbit, joins dwarves on a quest to reclaim a lost mountain kingdom, facing trolls, goblins, and a dragon while discovering courage.'), Books(title='She: A History of Adventure', author='H. Rider Haggard', yearPublished=1887, summary='An expedition into Africa encounters Ayesha, an immortal and terrifyingly powerful queen; a blend of adventure, mysticism, and Victorian imagination.'), Books(title='The Lion, the Witch and the Wardrobe', author='C. S. Lewis', yearPublished=1950, summary='Four siblings enter the magical land of Narnia through a wardrobe, joining Aslan to overthrow the White Witch and restore peace to the realm.')]\n"
     ]
    }
   ],
   "source": [
    "# Making the API call\n",
    "response = client.responses.parse(\n",
    "  model=\"gpt-5\",\n",
    "  instructions=system_prompt,\n",
    "  input=prompt,\n",
    "  text_format=BookResponseFormatJSON,\n",
    "  reasoning={\"effort\": \"minimal\"}\n",
    ")\n",
    "print(response.output_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lY4mHR4wQEzq",
    "outputId": "aa09936b-a3b5-45e8-b584-b77ca81d7570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.BookResponseFormatJSON'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response.output_parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B96g0Rxwqjc9",
    "outputId": "307f7306-956a-42be-c2aa-63657aa9b1f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Don Quixote' author='Miguel de Cervantes' yearPublished=1605 summary='A delusional hidalgo, inspired by chivalric romances, becomes a self-styled knight-errant and embarks on misadventures with his pragmatic squire, Sancho Panza, satirizing heroism and reality.'\n",
      "----------------------------------------------\n",
      "Don Quixote\n"
     ]
    }
   ],
   "source": [
    "print(response.output_parsed.Top10BestSellingBooks[0])\n",
    "print(\"----------------------------------------------\")\n",
    "print(response.output_parsed.Top10BestSellingBooks[0].title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nISPPdFA1WvX"
   },
   "source": [
    "## Strucutred output from PDF + OpenAI + pdf2images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7b8734184b8e4d55a7985249b2945606",
      "f01bf0f2ba75486cbc126b41e62c837b",
      "4badc600fb9b4211a7414e3417580fe0",
      "9d2cb22097ad4dd082ab79f65d23d7ba",
      "8d448337f0714fbc8f060d5187e31b83",
      "b106ed4ff1954b38a7f889d8254eb33f",
      "4354283ee09c4e2ebaaff6bc9b5717ba",
      "2f2ca30b04944fa0a8bbbc1584fbadef",
      "fbd658a77f4746b6ac1f9ab269a7a996",
      "324a99b6b9484893b74b399b37edf5b4",
      "c2fef0b4ef2a4a5fa00f7e6a00f5b443"
     ]
    },
    "id": "n3QpOuoOiMvB",
    "outputId": "c12f7446-a3c5-42bd-8543-47f2cb81b9e8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8734184b8e4d55a7985249b2945606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rag_research_paper.zip:   0%|          | 0.00/7.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "file_path = hf_hub_download(repo_id=\"jaiganesan/ai_tutor_knowledge\", filename=\"rag_research_paper.zip\",repo_type=\"dataset\",local_dir=\"/content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgQt32r8V50j",
    "outputId": "03d869ce-abe9-4edb-c058-b3ea032171d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/rag_research_paper.zip\n",
      "   creating: /content/rag_research_paper/\n",
      "  inflating: /content/rag_research_paper/2405.07437v2.pdf  \n",
      "  inflating: /content/rag_research_paper/2407.01219v1.pdf  \n",
      "  inflating: /content/rag_research_paper/2407.07858v1.pdf  \n",
      "  inflating: /content/rag_research_paper/2407.08223v1.pdf  \n",
      "  inflating: /content/rag_research_paper/2407.16833v1.pdf  \n",
      "  inflating: /content/rag_research_paper/2407.21712v1.pdf  \n",
      "  inflating: /content/rag_research_paper/2408.08067v2.pdf  \n",
      "  inflating: /content/rag_research_paper/2408.08921v1.pdf  \n"
     ]
    }
   ],
   "source": [
    "!unzip /content/rag_research_paper.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1Ogn8R7E5WZ"
   },
   "outputs": [],
   "source": [
    "system_instruction_prompt =\"\"\"\n",
    "You are an expert in extracting structured data from research paper PDFs.\n",
    "\n",
    "Task Description:\n",
    "Your task is to process an entire research paper provided as a PDF document and extract comprehensive, structured information from it. This includes all text, headlines, and detailed descriptions of visual elements. The final output must be a single, well-structured JSON object.\n",
    "\n",
    "Must Follow Guidelines:\n",
    "1.  Process the Entire PDF: Treat the input as a complete document, not as individual pages.\n",
    "2.  Accurate Data Extraction: Extract all text and information with high precision. Do not summarize, paraphrase, or omit any details.\n",
    "3.  Logical Structure: Organize the extracted content into logical sections based on the paper's structure (e.g., Abstract, Introduction, Methods, Results, Conclusion, Appendices).\n",
    "4.  Complete Information: Ensure no information is fragmented. Merge text that spans columns or pages into coherent paragraphs and sentences.\n",
    "\n",
    "Content Requirements:\n",
    "\n",
    "1.  Source Identification:\n",
    "    *   Accurately extract the arXiv ID (e.g., `arXiv:2405.07437v2`). Verify its correctness. If no arXiv ID is present, use `null`.\n",
    "\n",
    "2.  Headlines and Sections:\n",
    "    *   Extract all headlines and subheadlines to define the structure (e.g., \"1. Introduction,\" \"2.1. System Architecture\").\n",
    "    *   If a section of content has no visible headline, generate a descriptive title for it based on its content.\n",
    "    *   Each distinct section of the paper should become a separate object in the final JSON output.\n",
    "\n",
    "3.  Text Content:\n",
    "    *   For each section, extract the complete and verbatim text. Preserve all technical details, equations, and specific terminology.\n",
    "\n",
    "4.  Visual Elements (Figures, Tables, Graphs, Architectures):\n",
    "    *   Within the content of each section, when you encounter a visual element, provide a detailed analysis.\n",
    "    *   **Title/Caption:** Extract the exact title and caption.\n",
    "    *   **Detailed Description:** Describe the visual element's purpose and what it depicts.\n",
    "    *   **Key Information:** Detail the main trends, data points, comparisons, and conclusions shown. For architectures, describe the components, layers, and data flow.\n",
    "    *   **Contextual Insights:** Include any related insights or explanations from the surrounding text that refer to the visual element.\n",
    "\n",
    "Required Output Format (JSON):\n",
    "\n",
    "Your output must be a single JSON object that strictly adheres to the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"source_name\": \"Extract complete arXiv ID including prefix (e.g., arXiv:2405.07437v2). If none, use null.\",\n",
    "  \"source_id\": \"Extract complete arXiv ID including prefix (e.g., arXiv:2405.07437v2). If none, use null.\",\n",
    "  \"research_paper_data\": [\n",
    "    {\n",
    "      \"content_title\": \"The title of the first section (e.g., 'Abstract').\",\n",
    "      \"content\": \"The complete, verbatim text of the Abstract. Include descriptions of any visual elements if present.\"\n",
    "    },\n",
    "    {\n",
    "      \"content_title\": \"The title of the second section (e.g., '1. Introduction').\",\n",
    "      \"content\": \"The complete, verbatim text of the Introduction. This section should include detailed descriptions of any figures or tables found within it, as per the 'Visual Elements' guidelines.\"\n",
    "    },\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "  ]\n",
    "}\n",
    "```\n",
    "Key Guidelines:\n",
    "- Extract exact content without summarization\n",
    "- Ensure accuracy in complex technical details\n",
    "- Maintain logical content organization\n",
    "- Include complete visual element analysis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPKc_1JkwQfd"
   },
   "outputs": [],
   "source": [
    "# The response format- JSON schema\n",
    "class ResearchPaperData(BaseModel):\n",
    "  content_title: Optional[str] = Field(..., description=\"Extract or generate headlines and subheadlines (e.g., Abstract, Introduction, Methods, etc). Include section titles and subsection headings.\")\n",
    "  content: Optional[str] = Field(..., description=\"For each section: - Complete text content - Visual element descriptions - Figure/graph details: * Title/caption * Description * Key trends/comparisons * Architecture details * Related insights, Don't Summarize, Extract all the Content in the section\")\n",
    "\n",
    "class ResearchPaperResponseFormatJSON(BaseModel):\n",
    "  source_name: str = Field(..., description=\"Extract Research paper Title.\")\n",
    "  source_id: str = Field(..., description=\"Extract complete arXiv ID including prefix (e.g., arXiv:2405.07437v2). Verify ID accuracy multiple times. if there is no Arxiv ID return None\")\n",
    "  research_paper_data: List[ResearchPaperData] = Field(..., description=\"List of Extracted research paper data complete data without summarizing,\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQdjwxjT8Rb2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import json\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Parameters\n",
    "PDF_FOLDER = \"/content/rag_research_paper\"      # Folder containing multiple PDFs\n",
    "PAGES_PER_CHUNK = 5                             # Number of pages per chunk\n",
    "SYSTEM_INSTRUCTION = system_instruction_prompt  # Your system prompt\n",
    "RESPONSE_FORMAT = ResearchPaperResponseFormatJSON\n",
    "\n",
    "def split_pdf_by_pages(pdf_path, pages_per_chunk=PAGES_PER_CHUNK):\n",
    "    \"\"\"Split a single PDF into smaller page-range chunks.\"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    total_pages = len(reader.pages)\n",
    "    chunks = []\n",
    "\n",
    "    for start in range(0, total_pages, pages_per_chunk):\n",
    "        end = min(start + pages_per_chunk, total_pages)\n",
    "        writer = PdfWriter()\n",
    "        for page_idx in range(start, end):\n",
    "            writer.add_page(reader.pages[page_idx])\n",
    "        chunk_filename = f\"{os.path.splitext(os.path.basename(pdf_path))[0]}_\" \\\n",
    "                         f\"pages_{start+1}_{end}.pdf\"\n",
    "        chunk_path = os.path.join(\"/content\", chunk_filename)\n",
    "        with open(chunk_path, \"wb\") as f_out:\n",
    "            writer.write(f_out)\n",
    "        chunks.append({\"path\": chunk_path, \"pages\": f\"{start+1}-{end}\"})\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYtvX44N8XxV"
   },
   "outputs": [],
   "source": [
    "def process_pdf_chunk(chunk, system_instruction, response_format):\n",
    "    \"\"\"Call OpenAI API to extract structured data from a PDF chunk.\"\"\"\n",
    "    with open(chunk[\"path\"], \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-5\",\n",
    "        instructions=system_instruction,\n",
    "        text_format=response_format,\n",
    "        reasoning={\"effort\": \"minimal\"},\n",
    "        input=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": f\"Extract structured content from pages {chunk['pages']}.\"},\n",
    "                {\"type\": \"input_file\", \"filename\": os.path.basename(chunk[\"path\"]),\n",
    "                 \"file_data\": f\"data:application/pdf;base64,{b64}\"}\n",
    "            ]\n",
    "        }],\n",
    "    )\n",
    "    return response.output_parsed.research_paper_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeMovQC68d0v"
   },
   "outputs": [],
   "source": [
    "def convert_to_dict(obj):\n",
    "    \"\"\"Convert Pydantic model or custom object to dictionary.\"\"\"\n",
    "    if hasattr(obj, 'model_dump'):\n",
    "        # For Pydantic v2\n",
    "        return obj.model_dump()\n",
    "    elif hasattr(obj, 'dict'):\n",
    "        # For Pydantic v1\n",
    "        return obj.dict()\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        # For regular objects\n",
    "        return obj.__dict__\n",
    "    else:\n",
    "        # If it's already a basic type\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_eTVa5M8kW6",
    "outputId": "a49076eb-25d1-4bdb-8bae-6598dff51dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2407.07858v1.pdf...\n"
     ]
    }
   ],
   "source": [
    "# Main workflow\n",
    "all_results = {}\n",
    "pdf_paths = glob.glob(os.path.join(PDF_FOLDER, \"*.pdf\"))\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    pdf_name = os.path.basename(pdf_path)\n",
    "    print(f\"Processing {pdf_name}...\")\n",
    "    chunks = split_pdf_by_pages(pdf_path)\n",
    "    results = []\n",
    "    for chunk in chunks:\n",
    "        data = process_pdf_chunk(chunk, SYSTEM_INSTRUCTION, RESPONSE_FORMAT)\n",
    "        # Convert each ResearchPaperData object to a dictionary\n",
    "        for item in data:\n",
    "            results.append(convert_to_dict(item))\n",
    "    all_results[pdf_name] = results\n",
    "\n",
    "    # Remove the break if you want to process all PDFs**\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBfYOkx-tVvj",
    "outputId": "b9f575f9-dbcc-463b-cc33-e9a335ad69ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved structured data to 2407.07858v1_structured.json\n",
      "\n",
      "Cleaning up temporary chunk files...\n",
      "Removed: /content/2407.07858v1_pages_1_5.pdf\n",
      "Removed: /content/2407.07858v1_pages_6_8.pdf\n"
     ]
    }
   ],
   "source": [
    "# Save combined results for each PDF\n",
    "for pdf_name, data in all_results.items():\n",
    "    out_file = f\"{pdf_name.rsplit('.',1)[0]}_structured.json\"\n",
    "    with open(out_file, \"w\") as f_json:\n",
    "        json.dump(data, f_json, indent=2)\n",
    "    print(f\"Saved structured data to {out_file}\")\n",
    "\n",
    "print(\"\\nCleaning up temporary chunk files...\")\n",
    "for pdf_path in pdf_paths:\n",
    "    pdf_base = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    chunk_pattern = os.path.join(\"/content\", f\"{pdf_base}_pages_*.pdf\")\n",
    "    for chunk_file in glob.glob(chunk_pattern):\n",
    "        os.remove(chunk_file)\n",
    "        print(f\"Removed: {chunk_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDx-hRVctgHQ",
    "outputId": "e41c1223-681f-4bcd-e1ae-33de9e15cea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content_title': 'Title, Authors, Affiliation, Contact',\n",
       "  'content': 'FACTS About Building Retrieval Augmented Generation-based Chatbots\\nRama Akkiraju, Anbang Xu, Deepak Bora, Tan Yu, Lu An, Vishal Seth, Aaditya Shukla, Pritam Gundecha, Hridhay Mehta, Ashwin Jha, Prithvi Raj, Abhinav Balasubramanian, Murali Maram, Guru Muthusamy, Shivakesh Reddy Annepally, Sidney Knowles, Min Du, Nick Burnett, Sean Javiya, Ashok Marannan, Mamta Kumari, Surbhi Jha, Ethan Dereszenski, Anupam Chakraborty, Subhash Ranjan, Amina Terfai, Anoop Surya, Tracey Mercer, Vinodh Kumar Thanigachalam, Tamar Bar, Sanjana Krishnan, Jasmine Jaksic, Nave Algarici, Jacob Liberman, Joey Conway, Sonu Nayyar and Justin Boitano\\nNVIDIA\\n{rakkiraju,anbangx,dbora}@nvidia.com'},\n",
       " {'content_title': 'ABSTRACT',\n",
       "  'content': 'Enterprise chatbots, powered by generative AI, are rapidly emerg\\ufffeing as the most explored initial applications of this technology in the industry, aimed at enhancing employee productivity. Retrieval Augmented Generation (RAG), Large Language Models (LLMs), Langchain/Llamaindex types of LLM orchestration frameworks serve as key technological components in building generative-AI based chatbots. However, building successful enterprise chatbots is not easy. They require meticulous engineering of RAG pipelines. This includes fine-tuning semantic embeddings and LLMs, extract\\ufffeing relevant documents from vector databases, rephrasing queries, reranking results, designing effective prompts, honoring document access controls, providing concise responses, including pertinent references, safeguarding personal information, and building agents to orchestrate all these activities. In this paper, we present a frame\\ufffework for building effective RAG-based chatbots based on our first\\ufffehand experience of building three chatbots at NVIDIA: chatbots for IT and HR benefits, company financial earnings, and general enter\\ufffeprise content. Our contributions in this paper are three-fold. First, we introduce our FACTS framework for building enterprise-grade RAG-based chatbots that address the challenges mentioned. FACTS mnemonic refers to the five dimensions that RAG-based chatbots must get right - namely content freshness (F), architectures(A), cost economics of LLMs (C), testing (T), and security (S). Second, we present fifteen control points of RAG pipelines and techniques for optimizing chatbots’ performance at each stage. Finally, we present empirical results from our enterprise data on the accuracy\\ufffelatency tradeoffs between large LLMs vs small LLMs. To the best of our knowledge, this is the first paper of its kind that provides a holistic view of the factors as well as solutions for building secure enterprise-grade chatbots.'},\n",
       " {'content_title': '1 INTRODUCTION',\n",
       "  'content': 'Chatbots are increasingly becoming an extension of search tools in companies for finding relevant information. Whether it’s HR benefits, IT help, sales queries, or engineering issues, enterprise chatbots are now go-to productivity tools. Before the debut of OpenAI’s Chat-GPT [2] in November 2022, companies relied on internally developed chatbots based on dialog flows. Such bots re\\ufffequired extensive training for intent understanding and meticulous orchestration for response generation and yet could only provide extractive answers at best. These early bots, built on dialog man\\ufffeagement systems paired with information retrieval and question answering (IRQA) solutions were fragile and limited in capability. While previous generation language models and GPT models ex\\ufffeisted, they lacked the accuracy, robustness, and reliability needed for broad enterprise use [5].\\nChat-GPT’s release, the emergence of vector databases, and the wide-spread use of retrieval augmented generation (RAGs) [8] marked the beginning of a new era in Chatbot domain. Now, LLMs can understand user intents with simple prompts in natural lan\\ufffeguage, eliminating the need for complex intent variant training, syn\\ufffethesize enterprise content coherently, thereby empowering chatbots with conversational capability beyond scripted intent recognition. While LLMs bring their generative capabilities to construct coher\\ufffeent, factual, and logical responses to user queries, vector database\\ufffepowered information retrieval (IR) systems augment LLMs ability to retrieve fresh content. Tools like LangChain [1] and Llamaindex [9] facilitate chatbot construction, and orchestration of complex work\\ufffeflows including memory, agents, prompt templates, and overall flow. Together, vector-search based IR systems, LLMs, and LangChain\\ufffelike frameworks form core components of a RAG pipeline and are powering generative AI chatbots in post Chat-GPT era.\\nAt NVIDIA, our main motivation was to improve our employee productivity by building enterprise chatbots. Our initial enthusiasm quickly met with the reality of addressing numerous challenges. We learned that crafting a successful enterprise chatbot, even in post Chat-GPT era, while promising, is not easy. The process demands meticulous engineering of RAG pipelines, fine-tuning LLMs, and engineering prompts, ensuring relevancy and accuracy of enter\\ufffeprise knowledge, honoring document access control permissions, providing concise responses, including pertinent references, and safeguarding personal information. All of these require careful de\\ufffesign, skillful execution, and thorough evaluation, demanding many iterations. Additionally, maintaining user engagement while op\\ufffetimizing for speed and cost-efficiency is essential. Through our journey, we learned that getting an enterprise conversational vir\\ufffetual assistant right is akin to achieving a perfect symphony where every note carries significance!\\nIn this paper, we share our experiences and strategies in build\\ufffeing effective, secure, and cost-efficient chatbots. We answer the following questions from a practitioner perspective:\\narXiv:2407.07858v1 [cs.LG] 10 Jul 2024\\nTable 1: A summary of the three chatbots and the current state of development.\\nChatbot Domain Data Sources Data Types Access Control Sample Queries State\\nNVInfo Bot Enterprise Internal Knowledge SharePoint, GoogleDrive, Slack Confluence, ServiceNow, Jira etc. Docs, HTML PDFs, Slides Yes Can I park overnight in HQ parking lots? Early Access Testing\\nNVHelp Bot IT Help HR Benefits Knowledge Articles for ITHelp HR benefits pages Text, PDFs Docs Yes How to enroll in Employee Stock Purchase plan? Production\\nScout Bot Financial Earnings Company news, blogs, SEC filings Earnings-related interviews HTML, PDFs Docs No What are NVIDIA revenues for the past 3 years? Production\\n• What are the key challenges to consider when building and deploying enterprise-grade generative AI-based chatbots? We present our findings from trying to deliver fresh content (F) with flexible architectures (A) that are cost-efficient (C), tested well (T), and secure (S) - (FACTS).\\n• How to achieve user acceptable levels of quality with RAG systems in building chatbots? We present the fifteen control points of RAG pipelines and techniques for optimizing each control point and the overall RAG pipeline.'},\n",
       " {'content_title': '2 CASE STUDY',\n",
       "  'content': 'Our company’s content landscape includes both authoritative knowl\\ufffeedge and unauthoritative content. Authoritative content encom\\ufffepasses IT help articles, HR resources in platforms like ServiceNow, and project documentation on Confluence, SharePoint, Google Drive, and engineering tools like NVBugs and GitHub. Employee\\ufffegenerated content complements these sources on platforms such as Slack and MS Teams. In this paper, we present three bots that we have built at NVIDIA using RAGs and LLMs. These bots are briefly introduced below. All three bots are built on our in-house built generative-AI chatbot platform called NVBot platform. Some of the queries that our bots are capable of answering are shown in Table 1.\\n• NVInfo Bot answers questions about enterprise content (approx. 500M documents of size > 7 TB), complementing intranet search. It manages diverse data formats and en\\ufffeforces document access controls. The tech stack includes LangChain, a vendor vector database for retrieval and to handle document access controls, LLM model (multiple LLM models can be selected), and a custom web-UI.\\n• NVHelp Bot Bot focuses on IT help and HR benefits (approx. 2K multi-modal documents containing text, tables, images, pdfs, and html pages), using a similar tech stack to NVInfo bot with a smaller data volume.\\n• Scout Bot handles questions about financial earnings from public sources, managing structured and unstructured data (approx. 4K multi-modal documents containing text, tables, pdfs, and html pages). The tech stack includes an Open source Vector DB, LangChain, Ragas evaluation, selectable LLM models, and a custom web-UI.\\nIn the remainder of the paper, we present our FACTS frame\\ufffework that summarizes the challenges experienced and the learn\\ufffeings gained in building the aforementioned three chatbots. We first start with the challenge of dealing with delivering fresh enterprise content in each of the chatbots.'},\n",
       " {'content_title': '3 ENSURING FRESHNESS OF ENTERPRISE DATA IN LLM-POWERED CHATBOTS (F)',\n",
       "  'content': 'Ensuring the freshness of enterprise data in LLM-powered chatbots presents several challenges. Foundation models, although powerful, often fall short as they lack domain-specific and enterprise-specific knowledge. Once trained, these models are essentially frozen in time and may hallucinate, providing undesired or inaccurate information when used on enterprise content that they are not trained on.\\nRetrieval Augmented Generation (RAG) is a process where rel\\ufffeevant information is retrieved from vector databases through se\\ufffemantic matching and then fed to LLMs for response generation. In a RAG pipeline, vector databases and LLMs collaboratively en\\ufffesure the delivery of up-to-date enterprise knowledge. However, RAG pipelines have many control points, each of which when not tuned well can lead to lower accuracy, hallucinations, and irrele\\ufffevant responses by Chatbots. Additionally, document access control permissions complicate the search and retrieval process, requiring careful management to ensure data security and relevance. Fur\\ufffethermore, multi-modal content necessitates the use of multi-modal retrievers to handle structured, unstructured, and semi-structured data, including presentations, diagrams, videos, and meeting record\\ufffeings. Addressing these challenges is critical for maintaining the accuracy and reliability of enterprise chatbots. Inspired by [3], we identify fifteen control points of RAG from our case studies visual\\ufffeized in Figure 1. Each control point is labeled with a number. In the remainder of this section, we present our insights and learnings for addressing RAG control points.'},\n",
       " {'content_title': '3.1 Learnings',\n",
       "  'content': 'In figure 4, we present a summary description of the fifteen control points of RAG pipelines, challenges associated with each control point, and our suggested approaches for optimizing each control point. Each control point is labeled as RAG-C[num] and RAG\\ufffeOp[num] for RAG and RAGOps flows, respectively. Below, we present a few key learnings and insights to manage the fresh enter\\ufffeprise content.\\nMetadata Enrichment, Chunking, Query Rephrasal, Query Reranking: We noticed that metadata enrichment, chunking, query rephrasal and query re-ranking stages of RAG pipeline have the most impact on the quality of Chatbot responses. LLM response gen\\ufffeeration quality is highly dependent on retrieval relevancy. Retrieval relevancy is, in turn, highly dependent on document metadata en\\uffferichment, chunking, and query rephrasal. We implemented grid search-based auto-ML capabilities to find the right configurations of chunk token-sizes, experimented with various prompt variations, and explored different chunk reranking strategies to find optimal settings for each. While we have made significant improvements in retrieval relevancy and answer quality and accuracy, we believe, we still have more work to do to optimize the full pipeline.\\nHybrid Search: We noticed that Vector databases are not so good at handling matching entities (e.g., people names, places, company names etc.). Using a combination of Lexical search (e.g., elastic search) and vector search provided better retrieval relevancy and more coverage. Setting up an infrastructure that supports hybrid search capabilities, which combines the strengths of both lexical and vector-based searches, can enhance the accuracy and speed of the retrieval process.\\nAgentic Architectures: Questions such as ‘compare the revenue of NVIDIA from Q1 through Q4 of FY2024 and provide an analytical commentary on the key contributing factors that led to the changes in revenues during this time’ require complex agents that are capa\\ufffeble of query decomposition and orchestration. Figure 2 shows one mechanism we had implemented to deal with such questions in Scout bot. From our experience of building the three bots, we have realized that IR systems and LLMs are insufficient for answering complex queries. Complex agents and multi-agent architectures are needed to handle complex queries.\\nTo Fine-tune LLMs or not? A key decision is whether to fine\\ufffetune LLMs, balancing the use of foundational models with domain\\ufffespecific customizations. One size doesn’t fit all when it comes to LLMs. Some use cases may work well with foundational models, while others require customization. When considering customiza\\ufffetion, several options are available, including prompt engineering, P\\ufffetuning, parameter-efficient fine-tuning (PEFT), and full fine-tuning (FT). Fine-tuning requires significant investment in data labeling, training, and evaluations, each of which can be time-consuming and costly. Automating testing and quality evaluation processes be\\ufffecome critical to ensuring efficiency and accuracy when customizing LLMs. Figure 3 shows the accuracy vs latency tradeoff evaluations we have done comparing OpenAI’s GPT-4 model with some of the open-source models on about 245 queries from NVHelp bot do\\ufffemain. Our results show that the Llama3-70B model excels in several aspects of answer quality while maintaining acceptable latency.\\nHandling multi-modal data: Enterprise data is multi-modal. Han\\ufffedling structured, unstructured, and multi-modal data is crucial for a versatile RAG pipeline. From our experience, if the structure of the document is consistent and known apriori (like those found in EDGAR databases for SEC filings data in financial earnings domain that Scout bot was handling), implementing section-level splitting, using the section titles and subheadings and incoporating those in the context of chunks improves retrieval relevancy. We also found solutions like Unstructured.io, which specialize in extracting and structuring content from PDFs, helpful in parsing and chunking unstructured documents with context.\\nRAGOps: Effective health monitoring of RAG pipelines is essential once they are deployed. When answer quality is poor, a thorough error analysis is required to determine whether the issue lies in retrieval relevancy or LLM response generation. To debug retrieval relevancy, developers need detailed information on which chunks were stored in vector databases with their associated metadata, how queries were rephrased, which chunks were retrieved, and how those chunks were ranked. Similarly, if an LLM response is incorrect, it is crucial to review the final prompt used for answer generation. For issues with citations, developers must trace back to the original document links and their corresponding chunks. RAGOps/LLMOps and evaluation frameworks, such as Ragas, are critical for providing the necessary automation to enable rapid iteration during accuracy improvement cycles in RAG pipelines. More details on each control point are presented in Figure 4. In summary, while promising, implementing RAG systems for chat\\ufffebots demands meticulous planning and continuous evaluation to ensure secure and accurate data retrieval.'},\n",
       " {'content_title': 'Figure 1: Control Points in a typical RAG pipeline when building Chatbots. [Visual Element]',\n",
       "  'content': 'Title/Caption: Figure 1: Control Points in a typical RAG pipeline when building Chatbots.\\nDetailed Description: A flow diagram depicting a full RAG pipeline with numbered control points spanning ingestion to chat workflow and operations management. It shows sources (Source A, Source 2, …), continuous data ingestion, document store, GPU accelerated vector store, LLM deployments, and a chat workflow including query processing, reranking, context assembly, generation, citations, and post-processing. A separate lower band shows ChatBot Operations Management including ground truth creation, user feedback, evaluation dashboards, monitoring, error analysis, and improvement plan. A legend indicates model call, data flow, monitoring, and evaluation framework markers.\\nKey Information: The figure visually enumerates fifteen control points across RAG and RAGOps stages, including new content discovery, parsing/splitting, semantic splits/enrichment, chunking, embedding, retriever setup, hybrid search, reranker, context assembly, answer generation, citations, guardrails, post-processing, and monitoring. It emphasizes GPU-accelerated vector stores and LLM deployments for embeddings and generation.\\nContextual Insights: The text references Figure 1 as the visualization of the fifteen control points discussed and expanded in Figure 4.'},\n",
       " {'content_title': 'Figure 2: Agent architecture for handling complex queries [Visual Element]',\n",
       "  'content': 'Title/Caption: Figure 2: Agent architecture for handling complex queries\\nDetailed Description: A block diagram illustrating an agentic architecture used in the Scout bot to handle complex, multi-part queries. It includes components for query decomposition, sub-query orchestration, retrieval from enterprise knowledge tools, and aggregation/synthesis.\\nKey Information: Demonstrates the need for agents/multi-agent systems beyond simple IR + LLM for complex analytical questions, such as financial comparisons and commentary.\\nContextual Insights: Cited in the Learnings section to argue that complex agents are necessary for multi-step, analytical tasks.'},\n",
       " {'content_title': 'Figure 3: NVHelp answer quality and latency metrics comparison among different models [Visual Element]',\n",
       "  'content': 'Title/Caption: Figure 3: NVHelp answer quality and latency metrics com\\ufffeparison among different models\\nDetailed Description: A bar chart reporting answer quality metrics (Average Correctness, Average Helpfulness, Average Conciseness, Average Empathy) across multiple configurations/models, and a latency comparison table/plot showing response times in seconds for different agents/models (e.g., GPT-4 Agent, Llama3-70B, Mixtral-8x7B, etc.).\\nKey Information: Indicates Llama3-70B performing strongly on several quality dimensions with acceptable latency relative to larger commercial models. A latency list shows specific seconds for models; the chart presents comparative bars for quality metrics.\\nContextual Insights: Used to support the fine-tuning decision discussion and the claim that smaller/open-source models can meet quality needs with better latency.'},\n",
       " {'content_title': '4 BUILDING FLEXIBLE ARCHITECTURES FOR GENERATIVE AI CHATBOTS (A)',\n",
       "  'content': 'Keeping up with rapid progress in AI is like navigating a fast\\ufffemoving river. Every aspect, from vector databases and embedding models to LLMs, agentic architectures, low-code/no-code platforms, RAG evaluation frameworks, and prompting techniques, is evolving rapidly. Concurrently, departments within companies are exploring generative AI by building their own chatbots and AI copilots.\\nIn this dynamic environment, building common, flexible, and adaptive platforms are crucial. At NVIDIA, our chatbot ecosys\\ufffetem has grown significantly, reflecting a trend likely seen in many companies. From building three initial chatbots, we realized the importance of a common platform to avoid duplicated efforts in se\\ufffecurity, guardrails, authentication, prompts, user interfaces, feedback mechanisms, usage reporting, monitoring, and evaluations.\\nTo address this, we developed the NVBot platform (Figure 7), a modular platform with a pluggable architecture. It allows develop\\ufffeers to select LLMs, vector databases, embedding models, agents, and RAG evaluation frameworks that best suit their use case. It also provides common components for essential features like secu\\uffferity, guardrails, authentication, authorization, user experience, and monitoring. Additionally, the platform supports citizen develop\\ufffement, allowing multiple teams to contribute their tested prompts, workflows, guardrails, and fine-tuned models for collective use.\\nAs our ecosystem of bots expanded, we faced a critical question: should organizations build many domain-specific bots, a single enterprise bot, or go with a hybrid approach? Domain-specific chat\\ufffebots excel in tailored environments, while nterprise-wide chatbots act as generalists, providing a centralized knowledge base for all employees. Through our experience, we realized that there is no need to choose one over the other.\\nNovel architectural patterns are emerging where enterprise-wide chatbots act as ‘switchboards’, directing inquiries to specialized bots tuned with domain-specific data. This multibot architecture allows for the concurrent development of specialized chatbots while providing users with a unified interface. Our NVBot plat\\ufffeform supports the coexistence and orchestration of multiple chat\\ufffebots within an enterprise. The debate over a single bot or multi\\ufffeple specialized bots is ongoing. We envision a landscape where domain-specific bots coexist with a centralized information bot, supported by ’copilots’—generative AI capabilities integrated into workplace environments like programming IDEs and collabora\\ufffetion tools. At NVIDIA, we’re actively exploring all three chatbot variations—domain-specific, enterprise-wide, and copilot as genera\\ufffetive AI reshapes workplace efficiency and information accessibility.'},\n",
       " {'content_title': '5 COST ECONOMICS OF CHATBOT DEPLOYMENTS (C) [Section portion on pages 1-5]',\n",
       "  'content': 'Understanding the cost economics of generative AI-based chatbots involves several critical factors. The high costs of major and com\\ufffemercial LLMs can be unsustainable, with expenses adding up sig\\ufffenificantly across multiple use cases. Additionally, unseen expenses often accumulate as teams test various LLMs to meet specific needs. Moreover, when using commercial LLM vendor APIs, securing sensitive enterprise data requires guardrails to detect and prevent sensitive data leakage, as well as gateways for audit and legally permitted learning. There are also cost versus latency trade-offs to consider, as large LLMs with long context lengths typically have slower response times, impacting overall efficiency.\\nBigger Vs. Smaller Models: Larger, commercial LLMs, smaller open source LLMs are increasingly becoming viable for many use cases, thereby offering cost effective alternatives to companies. As opensource models are catching up with larger, commercial models, they are increasingly offering close-comparable accuracy, as demonstrated in our NVHelp bot emperical evaluation in Figure 3, and generally have better latency performance compared to larger models. Additionally, GPU optimization of inference models can further speed up processing times. Open-source models optimized with NVIDIA’s Tensor RT-LLM inference libraries, for instance, have shown faster performance than non-optimized models. These strategies help balance the need for cost-efficiency with maintaining high performance and security standards.\\nLLM Gateway: If you must use a vendor LLM API, it is better to implement an internal company LLM Gateway for audit, subscrip\\ufffetion and cost management across the company. Implementing an internal company LLM Gateway can streamline LLM usage, sub\\ufffescriptions, and data tracking for security audits. This central hub simplifies management and ensures efficient resource allocation. At NVIDIA IT, we have implemented an LLM Gateway that logs the inbound and outbound payloads for audit purposes and this data is guarded with access control permissions. Our LLM Gateway helps manage the subscriptions and costs of LLM API invocations.\\nIn summary, developing a hybrid and balanced LLM strategy is essential for managing costs and enabling innovation. This in\\ufffevolves using smaller and customized LLMs to manage expenses while allowing responsible exploration with large LLMs via an LLM Gateway. It’s crucial to measure and monitor ROI by keeping track of LLM subscriptions and costs, as well as assessing Gen-AI feature usage and productivity enhancements. Ensuring the security of sensitive enterprise data in cloud-based LLM usage requires imple\\ufffementing guardrails to prevent data leakage and building an LLM Gateway for audits and legally permitted learning. Finally, be aware of the trade-offs between cost, accuracy, and latency, customizing'},\n",
       " {'content_title': 'Figure 4: RAG control points, challenges, and remediations [Visual Element]',\n",
       "  'content': 'Title/Caption: Figure 4: RAG control points, challenges, and remediations\\nDetailed Description: A tabular figure listing RAG Stages, Description, Challenges, Remediations and Options. Rows cover RAG-C1 through RAG-C15 and associated RAGOps aspects, including data ingestion, data parsing, metadata enrichment, embedding model, LLM for metadata extraction, chunking, retriever storage, retriever setup, retrieval, chunk selection, context assembly, guardrails, answer generation, post processing and citations, and monitoring & logging.\\nKey Information: Enumerates concrete remediation strategies such as ACL support, smart HTML parsing, PII/PHI redaction, hybrid search, rerankers, multi-stage chunking, prompt-level guardrails, evaluation frameworks, telemetry, and dashboards.\\nContextual Insights: Referred to in Section 3.1 as the detailed summary of control points and optimizations.'},\n",
       " {'content_title': 'Figure 5: Scout Bot: Multi-part query [Visual Element]',\n",
       "  'content': 'Title/Caption: Figure 5: Scout Bot: Multi-part query\\nDetailed Description: A screenshot of the Scout bot interface showing a user question related to NVIDIA revenues from Q1 to Q4 FY2024 and whether records were set, and a bot response listing figures and percentage increase, followed by a list of sources with bullet links to NVIDIA announcements for each quarter.\\nKey Information: Demonstrates multi-part query handling, precise numerical answers, and citation of multiple source documents.\\nContextual Insights: Supports the discussion of agentic architectures and complex query orchestration in Section 3.1.'},\n",
       " {'content_title': 'Figure 6: NVHelp Bot: Answering questions on HR benefits [Visual Element]',\n",
       "  'content': 'Title/Caption: Figure 6: NVHelp Bot: Answering questions on HR benefits\\nDetailed Description: A screenshot of the NVHelp bot interface showing a question such as “How much does NVIDIA contribute to HSA?” and the bot’s answer explaining HSA contributions (up to $3,000, dependent on plan and dependents), contribution timing, and a list of related links in bullet form.\\nKey Information: Illustrates domain-specific bot providing concise, policy-based information with references.\\nContextual Insights: Used in Section 5 to exemplify practical chatbot outputs and the importance of citations and clarity.'},\n",
       " {'content_title': 'Figure 7',\n",
       "  'content': 'Figure 7: Architecture of NVBot platform upon which multiple chatbots are being built.\\n\\nVisual element description and details:\\n- Title/Caption: \"Figure 7: Architecture of NVBot platform upon which multiple chatbots are being built.\"\\n- Detailed Description: The figure depicts a layered architecture for the NVBot chatbot platform. At the top, users can access chatbots, copilots, and other tools via an enterprise bot that knows routes accordingly. Users can directly interact with chatbots and copilots. The next layer shows \"Chatbots and Copilots\" with examples like company directory, expense management, supply chain, sales copilot, marketing copilot, support copilot, executive copilot, agentic analytics, multi-agent platform, and more (ellipsis indicates additional bots). Below this sits the \"NVBot Chatbot Platform\" including components such as data ingestion pipelines, retrieval augmented generation (RAG) and multi-hop RAG, agentic analytics and agents, evaluation and guardrails, chat orchestration, integration with enterprise apps (e.g., Jira, Slack, Salesforce), and search/security & authentication. Under that is the \"Build-time Gen-AI workflow platform\" with tools like prompt engineering, evaluation, guardrails, SDK, governance, fine-tuning, and offline testing. The next foundational layer is \"Enterprise Data, Content Security & Cloud Platform\" listing LLM gateways, API gateways, content security guardrails, automatic data labeling & classification, and others. Supporting layers include \"Opensource frameworks and tools\" (e.g., LangChain, LlamaIndex, Vector DBs, and related OSS) and \"Vendor products\" (commercial offerings). At the bottom are platform foundations: \"NeMo GenAI Software\" (NVIDIA NeMo, NeMo Framework, Guardrails, NeMo Inference, Cloud Native Stack, Chatbot Engine...) and \"NVIDIA Cloud Foundations\" (NVIDIA DGX, NVIDIA Accelerators, NVIDIA Systems, NGC, on-prem/Clouds). On the left, an \"Enterprise Knowledge & Apps\" block indicates data sources like Confluence, SharePoint, and other repositories feeding into the system. A \"Developer\" icon at lower left indicates build-time interactions. Arrows show data and control flow from enterprise knowledge and developer inputs into the platform and up to user-facing chatbots.\\n- Key Information: The architecture emphasizes modularity across layers: user interaction, chatbot/coprots catalog, platform services (RAG, agents, orchestration, evaluation, guardrails), build-time tooling (prompting, SDKs, governance, fine-tuning, testing), enterprise data/security compliance (ACLs, labeling), and infrastructure/software stacks (NeMo, DGX, cloud). It highlights integration with enterprise apps and strong guardrailing/security.\\n- Contextual Insights: Surrounding text discusses smaller LLMs matching accuracy of larger models with latency trade-offs and sets the stage for subsequent sections on testing and security.'},\n",
       " {'content_title': 'Continuing text below Figure 7',\n",
       "  'content': 'smaller LLMs to match the accuracy of larger models while not\\xading that large LLMs with long context lengths tend to have longer response time.'},\n",
       " {'content_title': '6 TESTING RAG-BASED CHATBOTS (T)',\n",
       "  'content': 'Testing generative AI solutions can be a lengthy process due to the need for human response validation. LLMs are increasingly being employed using ‘LLM-as-a-judge’ approach. However, it is advisable to use caution when using LLMs as human proxy, as using LLMs as judges can lead to self-fulfilling prophecy type of scenarios reinforcing their inherent biases in evaluations as well.\\n• Security Testing: Automating security testing is critical for maintaining development velocity without compromising safety. A strong security framework and regression test datasets ensure that the chatbot remains resilient to potential threats. We are collaborating with our internal RED teams in security to prepare a set of datasets that can be tested with each major iteration of the chatbot.\\n• Prompt Change Testing: Generative AI models can be highly sensitive to prompt changes. To maintain accuracy, full regression testing is needed with each prompt alteration.\\n• Feedback Loops: Incorporating feedback gathered and the RLHF cycle is pivotal for continuous improvement. It allows LLM models to refine both our solutions and Language Models over time, ensuring that the chatbot becomes increasingly proficient. However, if the chosen foundational models don’t offer customization, then it becomes difficult to align the models to human feedback. If the feedback is significant and comes in many areas, then model customization may be an option. As of now, we have begun gathering user feedback but haven’t built our continuous learning pipelines using RLHF yet. Having tools to make this automated is critical to pos-production life cycle management of these chatbots.'},\n",
       " {'content_title': '6.1 Learnings',\n",
       "  'content': 'Plan for Long Test Cycles: Effective testing of RAG-based chat\\xadbots requires anticipation of lengthy test cycles. Begin by focusing on automating tests and enhancing accuracy assessments to stream\\xadline this essential phase.\\nBuild Representative Ground Truth Datasets: It is crucial to construct comprehensive ground truth datasets that reflect full spectrum of targeted solution strengths. This ensures that the chatbot is tested against scenarios that it will encounter in actual use.\\nAutomate Evaluations: While leveraging LLMs as evaluators can provide scalable testing options, remember that the quality of human evaluations is unmatched. Automated tools should be used where feasible to supplement but not replace human oversight.\\nIncorporate Human Feedback and Continuous Learning: Es\\xadtablish mechanisms that allow for human feedback and systematic error analysis. Prioritize iterative improvements based on this feed\\xadback to continually refine chatbot performance and adaptability.'},\n",
       " {'content_title': '7 SECURING RAG-BASED CHATBOTS (S)',\n",
       "  'content': 'Building trust is paramount when deploying generative AI chatbots. To mitigate risks, guardrails for hallucinations, toxicity, fairness, transparency, and security are critical. Strong foundational models are increasingly getting better at these guardrails. However, there are still many possibilities of jail breaks, adversarial attacks, and other security issues. Apart from these security risks, generative AI\\xadbased chatbots are susceptible to derivative risks (explained below). Since our bots are all internal enterprise chatbots, our focus has been more on the enterprise content security and guardrailing for sensitive data. Below we summarize our learnings and insights for securing RAG-based chatbots based on our experience. Addressing these challenges is imperative to maintaining the integrity and security of RAG-based chatbots within corporate environments.'},\n",
       " {'content_title': '7.1 Learnings',\n",
       "  'content': 'Enterprise Content Access Control: Enterprise documents are protected by access controls, requiring RAG-based chatbots to com\\xadply with Access Control Lists (ACLs) during response generation. To ensure this compliance, we specifically selected an IR product known for its capability to honor these document ACLs effectively.\\nDerivative Risks with Generative AI: Chatbots might gener\\xadate responses that lack context from their original data sources, potentially leading to misinterpretations. Additionally, enhanced search methods could inadvertently elevate the risk of exposing sensitive data if enterprise content is inappropriately secured. As part of our NVInfo bot journey, we implemented sensitive data guardrails in addition to leveraging sensitive data filtering and clas\\xadsification capabilities provided by the vector search solution we used to automatically filter out sensitive data during the retrieval.\\nData Governance and Content Security: Efficient knowledge ac\\xadcess can increase sensitive data leakage risks. Thus, it’s essential to prioritize data governance before deployment to safeguard against unauthorized access and data breaches. At NVIDIA, we embarked on an enterprise content security initiative for document sensitivity classification and exclusion of sensitive content from chatbots.\\nEnterprise Guardrailing: Implementing guardrails that align gen\\xaderative AI responses with specific enterprise policies and rules is essential. These guardrails help mitigate risks by ensuring that Chatbot-generated content adheres to established norms and ethi\\xadcal guidelines, preventing potential legal and reputational damage. In NVInfo bot, we implemented many guardrails in LLM prompts initially. However, later realized that not all LLMs follow these prompts consistently. Therefore, we implemented these guardrails during pre and post processing of queries and responses respec\\xadtively using Nemo Guardrails [13].'},\n",
       " {'content_title': '8 RELATED WORK',\n",
       "  'content': 'Our work can be compared with RAG papers on various topics dealing with RAG quality along all the FACTS dimensions we pre\\xadsented (freshness, architecture, costs, testing and security). Due to lack of space, we contrast our work with selective works. Bar\\xadnett et. al. [3] presented seven failure points when engineering RAG systems. In their work, they highlight the challenges of getting re\\xadtrieval augmented generation right by presenting their findings from having built three chatbots. Wenqi Glantz [6] elaborated 12 RAG pain points and presented solutions. We experienced similar challenges first-hand when building our chatbots. However, none of these works discuss the challenges with complex queries, testing, dealing with document security, and the need for flexible archi\\xadtectures. In our work, we not only build on failure/pain points of RAGs as mentioned above, but also present our 15 control points in RAG pipelines and offer specific solutions for each stage. Also, we extend our insights and present practical techniques for handling complex queries, testing, and security. We present a reference ar\\xadchitecture for one of the implementations of agentic architectures for complex query handling, strategies for testing and evaluating subjective query responses, and raised awareness for dealing with document ACLs and security. Furthermore, we present a reference architecture for a flexible generative-AI based Chatbot platform.\\nChipNemo [10] presents evidence for using a domain adapted language model for improving RAG’s performance on domain spe\\xadcific questions. They finetuned the e5-small-unsupervised model with 3,000 domain specific auto-generated samples. We tried fine\\xadtuning e5-large embeddings model in Scout Bot. Our results did not demonstrate significant improvements. We are presently collecting high quality human-annotated data to repeat the experiments. This could be an important direction to explore in the future for our work. Another interesting technique was presented by Setty et. al. [15], in improving RAG performance using Hypothetical Docu\\xadment Embeddings (HYDE) technique. HyDE uses an LLM to gener\\xadate a theoretical document when responding to a query and then does the similarity search with both the original question and hy\\xadpothetical answer. This is a promising approach but might make the architecture complex.\\nActive Retrieval augmented generation (FLARE) [7] iteratively synthesizes a hypothetical next sentence. If the generated sentence contains low-probability tokens, FLARE would use the sentence as the new query for retrieval and regenerate the sentence. Mialon et al. [12] reviews works for advanced augmented generation methods in language model. Self-refine [11] builds an agent to improve the initial answer of RAG through iterative feedback and refinement. ReAct [16] Agent is widely used for handling the complex queries in a recursive manner. On the RAG evaluation front, RAGAS [4] and ARES [14] utilize LLMs as judges and build automatic RAG benchmark to evaluate the RAG system. Zhu et al. [17] overview the intensive usages of LLM in a RAG pipeline including retriever, data generation, rewriter, and reader. We believe that our work provides a unique perspective on building secure enterprise-grade chatbots via our FACTS framework.'},\n",
       " {'content_title': '9 CONCLUSIONS',\n",
       "  'content': 'In this paper, we presented our approach to developing effective RAG-based chatbots, highlighting our experiences of building three chatbots at NVIDIA. We outlined our FACTS framework, empha\\xadsizing the importance of content freshness (F), architecture (A), LLM cost (C) management, planning for testing (T), and security (S) in creating robust, secure, and enterprise-grade chatbots. We also identified and elaborated on fifteen critical control points within RAG pipelines, providing strategies to enhance chatbot perfor\\xadmance at each stage. Furthermore, our empirical analysis reveals the trade-offs between accuracy and latency when comparing large and small LLMs. This paper offers a holistic perspective on the essential factors and practical solutions for building secure and efficient enterprise-grade chatbots, making a unique contribution to the field. More work is needed in several areas to build effective RAG-based chatbots. This includes developing agentic architectures for handling complex, multi-part, and analytical queries; efficiently summarizing large volumes of frequently updated enterprise data; incorporating auto-ML capabilities to optimize various RAG control points automatically; and creating more robust evaluation frame\\xadworks for assessing subjective responses and conversations.'},\n",
       " {'content_title': 'REFERENCES',\n",
       "  'content': '[1] Langchain. https://github.com/langchain-ai.\\n[2] Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023).\\n[3] Barnett, S., Kurniawan, S., Thudumu, S., Brannelly, Z., and Abdelrazek, M. Seven failure points when engineering a retrieval augmented generation system. arXiv preprint arXiv:2401.05856 (2024).\\n[4] Es, S., James, J., Espinosa-Anke, L., and Schockaert, S. Ragas: Automated evaluation of retrieval augmented generation. arXiv preprint arXiv:2309.15217 (2023).\\n[5] Galitsky, B. Developing enterprise chatbots. Springer, 2019.\\n[6] Glantz, W. 12 rag pain points and proposed solutions.\\n[7] Jiang, Z., Xu, F. F., Gao, L., Sun, Z., Liu, Q., Dwivedi-Yu, J., Yang, Y., Callan, J., and Neubig, G. Active retrieval augmented generation. arXiv preprint arXiv:2305.06983 (2023).\\n[8] Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küt\\xadtler, H., Lewis, M., Yih, W.-t., Rocktäschel, T., et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33 (2020), 9459–9474.\\n[9] Liu, J. LlamaIndex. ℎ𝑡𝑡𝑝𝑠 : //𝑔𝑖𝑡ℎ𝑢𝑏.𝑐𝑜𝑚/𝑗𝑒𝑟𝑟 𝑦𝑗𝑙𝑖𝑢/𝑙𝑙𝑎𝑚𝑎𝑖𝑛𝑑𝑒𝑥 (2022).\\n[10] Liu, M., Ene, T.-D., Kirby, R., Cheng, C., Pinckney, N., Liang, R., Alben, J., Anand, H., Banerjee, S., Bayraktaroglu, I., et al. Chipnemo: Domain-adapted llms for chip design. arXiv preprint arXiv:2311.00176 (2023).\\n[11] Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S., Yang, Y., et al. Self-refine: Iterative refinement with self-feedback. Advances in Neural Information Processing Systems 36 (2024).\\n[12] Mialon, G., Dessì, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu, R., Rozière, B., Schick, T., Dwivedi-Yu, J., Celikyilmaz, A., et al. Augmented language models: a survey. arXiv preprint arXiv:2302.07842 (2023).\\n[13] Rebedea, T., Dinu, R., Sreedhar, M., Parisien, C., and Cohen, J. Nemo guardrails: A toolkit for controllable and safe llm applications with programmable rails. arXiv preprint arXiv:2310.10501 (2023).\\n[14] Saad-Falcon, J., Khattab, O., Potts, C., and Zaharia, M. Ares: An automated evaluation framework for retrieval-augmented generation systems. arXiv preprint arXiv:2311.09476 (2023).\\n[15] Setty, S., Jijo, K., Chung, E., and Vidra, N. Improving retrieval for rag based question answering models on financial documents. arXiv preprint arXiv:2404.07221 (2024).\\n[16] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629 (2022).\\n[17] Zhu, Y., Yuan, H., Wang, S., Liu, J., Liu, W., Deng, C., Dou, Z., and Wen, J.- R. Large language models for information retrieval: A survey. arXiv preprint arXiv:2308.07107 (2023).'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results['2407.07858v1.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vxh1DRs64lB",
    "outputId": "68155081-023d-4e7c-c7d2-5c5ff9798b8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_results['2407.07858v1.pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbsEyZXJ7q3Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
